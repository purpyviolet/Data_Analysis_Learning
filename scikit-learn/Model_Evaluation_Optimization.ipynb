{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Scores: [0.88  0.915 0.92  0.93  0.905]\n",
      "StratifiedKFold Scores: [0.88  0.915 0.9   0.945 0.895]\n",
      "TimeSeriesSplit Scores: [0.87349398 0.90963855 0.88554217 0.87349398 0.91566265]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# KFold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_kfold = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# StratifiedKFold Cross-Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores_skfold = cross_val_score(model, X, y, cv=skf)\n",
    "\n",
    "# TimeSeriesSplit Cross-Validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "scores_tscv = cross_val_score(model, X, y, cv=tscv)\n",
    "\n",
    "# Print results\n",
    "print(\"KFold Scores:\", scores_kfold)\n",
    "print(\"StratifiedKFold Scores:\", scores_skfold)\n",
    "print(\"TimeSeriesSplit Scores:\", scores_tscv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\epiph\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 9 is smaller than n_iter=50. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters from GridSearchCV: {'max_depth': None, 'n_estimators': 200}\n",
      "Best parameters from RandomizedSearchCV: {'n_estimators': 200, 'max_depth': 10}\n",
      "Best parameters from HalvingGridSearchCV: {'max_depth': 20, 'n_estimators': 50}\n",
      "Best parameters from HalvingRandomSearchCV: {'n_estimators': 100, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Define model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=5, random_state=42, cv=5)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# HalvingGridSearchCV\n",
    "halving_grid_search = HalvingGridSearchCV(estimator=model, param_grid=param_grid, cv=5, factor=2, random_state=42)\n",
    "halving_grid_search.fit(X, y)\n",
    "\n",
    "# HalvingRandomSearchCV\n",
    "halving_random_search = HalvingRandomSearchCV(estimator=model, param_distributions=param_grid, cv=5, factor=2, random_state=42)\n",
    "halving_random_search.fit(X, y)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "print(\"Best parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"Best parameters from HalvingGridSearchCV:\", halving_grid_search.best_params_)\n",
    "print(\"Best parameters from HalvingRandomSearchCV:\", halving_random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "ROC AUC: 1.0\n",
      "Mean Squared Error: 1.0530152478596555\n",
      "Mean Absolute Error: 0.8181060788054686\n",
      "R2 Score: -3.2120778397499823\n",
      "Silhouette Score: 0.11500836462407422\n",
      "Adjusted Rand Index: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    silhouette_score, adjusted_rand_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Generate predictions\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "y_proba = model.predict_proba(X)[:, 1]  # Probabilities for ROC AUC\n",
    "\n",
    "# Classification Metrics\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "roc_auc = roc_auc_score(y, y_proba)\n",
    "\n",
    "# Print classification metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# Regression Metrics\n",
    "y_regression = y + np.random.randn(len(y))  # Simulate continuous target\n",
    "mse = mean_squared_error(y, y_regression)\n",
    "mae = mean_absolute_error(y, y_regression)\n",
    "r2 = r2_score(y, y_regression)\n",
    "\n",
    "# Print regression metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "# Clustering Metrics\n",
    "labels_true = y  # Assume true labels\n",
    "labels_pred = y_pred  # Assume predicted labels\n",
    "silhouette = silhouette_score(X, labels_pred)\n",
    "ari = adjusted_rand_score(labels_true, labels_pred)\n",
    "\n",
    "# Print clustering metrics\n",
    "print(\"Silhouette Score:\", silhouette)\n",
    "print(\"Adjusted Rand Index:\", ari)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是 **模型评估与优化** 各个部分的代码示例，并分块详细解释其原理：\n",
    "\n",
    "---\n",
    "\n",
    "### **1. 交叉验证**\n",
    "#### **原理**\n",
    "1. **KFold**:\n",
    "   - 将数据随机分为 \\(k\\) 折，逐次用 \\(k-1\\) 折作为训练集，剩余 1 折作为测试集。\n",
    "   - **适用场景**: 数据量适中，无明显类别不平衡。\n",
    "\n",
    "2. **StratifiedKFold**:\n",
    "   - 在每折中保持类别比例一致。\n",
    "   - **适用场景**: 分类任务中类别不平衡。\n",
    "\n",
    "3. **TimeSeriesSplit**:\n",
    "   - 适用于时间序列数据，确保训练集早于测试集。\n",
    "   - **适用场景**: 时间序列建模。\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 超参数调优**\n",
    "#### **原理**\n",
    "1. **GridSearchCV**:\n",
    "   - 遍历所有参数组合，使用交叉验证选择最佳参数。\n",
    "   - **优点**: 保证找到全局最优参数。\n",
    "   - **缺点**: 参数组合多时计算量大。\n",
    "\n",
    "2. **RandomizedSearchCV**:\n",
    "   - 随机选择部分参数组合进行搜索。\n",
    "   - **优点**: 快速，适合大规模参数空间。\n",
    "   - **缺点**: 可能漏掉最佳参数。\n",
    "\n",
    "3. **HalvingGridSearchCV**:\n",
    "   - 使用逐步增大的数据集和参数子集进行搜索。\n",
    "   - **优点**: 快速优化参数。\n",
    "\n",
    "4. **HalvingRandomSearchCV**:\n",
    "\n",
    "   - 与 HalvingGridSearchCV 类似，但随机选择参数组合。\n",
    "   - 适合大规模参数搜索。\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 模型评估指标**\n",
    "#### **原理**\n",
    "1. **分类指标**:\n",
    "   - `accuracy_score`: 分类准确率。\n",
    "   - `precision_score`: 正类中预测正确的比例。\n",
    "   - `recall_score`: 所有正类中预测正确的比例。\n",
    "   - `f1_score`: 精确率和召回率的调和平均值。\n",
    "   - `roc_auc_score`: 评估模型的分类能力，尤其是概率输出。\n",
    "\n",
    "2. **回归指标**:\n",
    "   - `mean_squared_error`: 均方误差，用于评估回归预测的偏差。\n",
    "   - `mean_absolute_error`: 平均绝对误差，衡量预测的平均绝对偏差。\n",
    "   - `r2_score`: 判定系数，表示模型的拟合优度。\n",
    "\n",
    "3. **聚类指标**:\n",
    "   - `silhouette_score`: 衡量聚类的紧密性和分离性。\n",
    "   - `adjusted_rand_score`: 衡量聚类结果与真实标签的一致性。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
