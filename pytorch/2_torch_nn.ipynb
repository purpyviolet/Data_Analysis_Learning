{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containers\n",
    "Module：所有神经网络模块的基类，用于构建自定义模型。\n",
    "\n",
    "Sequential：按顺序组合多个子模块，适用于线性堆叠的模型。\n",
    "\n",
    "ModuleList：存储任意数量的子模块，适用于需要动态管理模块的场景。\n",
    "\n",
    "ModuleDict：以字典形式存储子模块，适用于需要通过键访问模块的场景。\n",
    "\n",
    "ParameterList：存储一系列参数，适用于需要动态管理参数的场景。\n",
    "\n",
    "ParameterDict：以字典形式存储参数，适用于需要通过键访问和管理参数的场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 自定义的神经网络继承自 nn.Module\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)  # 定义一个线性层\n",
    "        self.fc2 = nn.Linear(5, 2)   # 定义另一个线性层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # 使用 ReLU 激活函数\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 使用 Sequential 构建模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 2)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): ModuleList(\n",
      "    (0-2): 3 x Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(10, 10) for _ in range(3)])  # 三个线性层\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = torch.relu(layer(x))  # 依次应用每个线性层\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layers): ModuleDict(\n",
      "    (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (fc2): Linear(in_features=5, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'fc1': nn.Linear(10, 5),\n",
    "            'fc2': nn.Linear(5, 2)\n",
    "        })\n",
    "\n",
    "    def forward(self, x, layer_name):\n",
    "        x = torch.relu(self.layers[layer_name](x))  # 根据键名选择层\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (params): ParameterList(\n",
      "      (0): Parameter containing: [torch.float32 of size 10x10]\n",
      "      (1): Parameter containing: [torch.float32 of size 10x10]\n",
      "      (2): Parameter containing: [torch.float32 of size 10x10]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for _ in range(3)])  # 三个参数，parameterList一般放的都是矩阵，与ModuleList不同\n",
    "\n",
    "    def forward(self, x):\n",
    "        for param in self.params:\n",
    "            x = x @ param  # 矩阵乘法\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (params): ParameterDict(\n",
      "      (weight1): Parameter containing: [torch.FloatTensor of size 10x5]\n",
      "      (weight2): Parameter containing: [torch.FloatTensor of size 5x2]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.params = nn.ParameterDict({\n",
    "            'weight1': nn.Parameter(torch.randn(10, 5)),\n",
    "            'weight2': nn.Parameter(torch.randn(5, 2))\n",
    "        })\n",
    "\n",
    "    def forward(self, x, param_name):\n",
    "        x = x @ self.params[param_name]  # 根据键名选择参数\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积层（Convolution Layers）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 48])\n"
     ]
    }
   ],
   "source": [
    "# nn.Conv1d\n",
    "# 1D卷积层应用于一维信号（如时间序列、音频信号）。它对多个输入平面（通道）上的输入信号进行一维卷积操作，提取局部特征。\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv1d = nn.Conv1d(in_channels=16, out_channels=33, kernel_size=3)\n",
    "input_signal = torch.randn(20, 16, 50)  # (batch_size, in_channels, signal_length)\n",
    "output = conv1d(input_signal) # 这里只改变了通道数，长度由于kernelsize也会减小\n",
    "print(output.shape)  # 输出形状: (20, 33, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# nn.Conv2d\n",
    "# 2D卷积层用于处理二维输入（如图像）。它在每个输入通道上应用二维卷积操作，非常适合图像处理。\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "image = torch.randn(10, 3, 32, 32)  # (batch_size, in_channels, height, width)\n",
    "output = conv2d(image)# 这里只改变了通道数，长度由于kernelsize也会减小\n",
    "print(output.shape)  # 输出形状: (10, 16, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Conv3d\n",
    "# 3D卷积层用于三维数据（如视频或三维医疗图像），在三个维度上执行卷积操作。\n",
    "conv3d = nn.Conv3d(in_channels=1, out_channels=8, kernel_size=3)\n",
    "volume = torch.randn(4, 1, 16, 32, 32)  # (batch_size, in_channels, depth, height, width)\n",
    "output = conv3d(volume)\n",
    "print(output.shape)  # 输出形状: (4, 8, 14, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 33, 52])\n",
      "torch.Size([10, 8, 34, 34])\n",
      "torch.Size([4, 1, 18, 34, 34])\n"
     ]
    }
   ],
   "source": [
    "# nn.ConvTranspose1d\n",
    "# 1D反卷积层（又称转置卷积或反向卷积）用于增大一维信号的尺寸，常用于上采样（例如生成模型中的解卷积）。\n",
    "conv_transpose1d = nn.ConvTranspose1d(in_channels=16, out_channels=33, kernel_size=3)\n",
    "input_signal = torch.randn(20, 16, 50)\n",
    "output = conv_transpose1d(input_signal)# 主要的不同就是原信号的长度增加了\n",
    "print(output.shape)  # 输出形状: (20, 33, 52) \n",
    "\n",
    "# nn.ConvTranspose2d\n",
    "# 2D反卷积用于二维数据（如图像）的上采样，常用于卷积神经网络（CNN）中的生成模型。\n",
    "\n",
    "conv_transpose2d = nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3)\n",
    "image = torch.randn(10, 16, 32, 32)\n",
    "output = conv_transpose2d(image)\n",
    "print(output.shape)  # 输出形状: (10, 8, 34, 34)\n",
    "\n",
    "# nn.ConvTranspose3d\n",
    "# 3D反卷积用于三维数据的上采样，适合三维体积数据的生成。\n",
    "\n",
    "conv_transpose3d = nn.ConvTranspose3d(in_channels=8, out_channels=1, kernel_size=3)\n",
    "volume = torch.randn(4, 8, 16, 32, 32)\n",
    "output = conv_transpose3d(volume)\n",
    "print(output.shape)  # 输出形状: (4, 1, 18, 34, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lazy_conv2d = nn.LazyConv2d(out_channels=16, kernel_size=3)\n",
    "image = torch.randn(10, 3, 32, 32)  # (batch_size, in_channels, height, width)\n",
    "output = lazy_conv2d(image)  # 自动推断 in_channels 为 3\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始图像：\n",
      " tensor([[[[ 0.,  1.,  2.,  3.],\n",
      "          [ 4.,  5.,  6.,  7.],\n",
      "          [ 8.,  9., 10., 11.],\n",
      "          [12., 13., 14., 15.]],\n",
      "\n",
      "         [[16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23.],\n",
      "          [24., 25., 26., 27.],\n",
      "          [28., 29., 30., 31.]],\n",
      "\n",
      "         [[32., 33., 34., 35.],\n",
      "          [36., 37., 38., 39.],\n",
      "          [40., 41., 42., 43.],\n",
      "          [44., 45., 46., 47.]]]])\n",
      "Unfold 结果：\n",
      " tensor([[[ 0.,  1.,  2.,  4.,  5.,  6.,  8.,  9., 10.],\n",
      "         [ 1.,  2.,  3.,  5.,  6.,  7.,  9., 10., 11.],\n",
      "         [ 4.,  5.,  6.,  8.,  9., 10., 12., 13., 14.],\n",
      "         [ 5.,  6.,  7.,  9., 10., 11., 13., 14., 15.],\n",
      "         [16., 17., 18., 20., 21., 22., 24., 25., 26.],\n",
      "         [17., 18., 19., 21., 22., 23., 25., 26., 27.],\n",
      "         [20., 21., 22., 24., 25., 26., 28., 29., 30.],\n",
      "         [21., 22., 23., 25., 26., 27., 29., 30., 31.],\n",
      "         [32., 33., 34., 36., 37., 38., 40., 41., 42.],\n",
      "         [33., 34., 35., 37., 38., 39., 41., 42., 43.],\n",
      "         [36., 37., 38., 40., 41., 42., 44., 45., 46.],\n",
      "         [37., 38., 39., 41., 42., 43., 45., 46., 47.]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Unfold\n",
    "# Unfold 从输入张量中提取滑动窗口的局部块，非常适合在卷积操作或图像处理时获取局部区域信息。\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个 4x4 的图像，3 通道\n",
    "image = torch.arange(3*4*4).view(1, 3, 4, 4).float()\n",
    "print(\"原始图像：\\n\", image)\n",
    "\n",
    "# Unfold操作：提取 2x2 的局部区域\n",
    "unfold = nn.Unfold(kernel_size=2)\n",
    "output = unfold(image)\n",
    "print(\"Unfold 结果：\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 重构后的图像：\n",
      " tensor([[[[  0.,   2.,   4.,   3.],\n",
      "          [  8.,  20.,  24.,  14.],\n",
      "          [ 16.,  36.,  40.,  22.],\n",
      "          [ 12.,  26.,  28.,  15.]],\n",
      "\n",
      "         [[ 16.,  34.,  36.,  19.],\n",
      "          [ 40.,  84.,  88.,  46.],\n",
      "          [ 48., 100., 104.,  54.],\n",
      "          [ 28.,  58.,  60.,  31.]],\n",
      "\n",
      "         [[ 32.,  66.,  68.,  35.],\n",
      "          [ 72., 148., 152.,  78.],\n",
      "          [ 80., 164., 168.,  86.],\n",
      "          [ 44.,  90.,  92.,  47.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Fold操作：将 2x2 的局部区域重新组合成原始形状\n",
    "fold = nn.Fold(output_size=(4, 4), kernel_size=2)\n",
    "reconstructed_image = fold(output)\n",
    "print(\"Fold 重构后的图像：\\n\", reconstructed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Max Pooling (最大池化)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 2D Max Pooling 示例\n",
    "x = torch.randn(1, 1, 4, 4)  # 输入 1x1x4x4 的图像\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2) # 一般kernel_size和stride相同\n",
    "output = pool(x)\n",
    "print(output.shape)  # 输出大小变为 1x1x2x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# 2D Average Pooling 示例\n",
    "x = torch.randn(1, 1, 4, 4)\n",
    "pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "output = pool(x)\n",
    "print(output.shape)  # 输出大小也是 1x1x2x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# 自适应池化允许你指定输出的大小，而不是窗口的大小。它会根据输入尺寸自动计算适合的窗口大小和步幅，确保输出的大小固定。\n",
    "\n",
    "# nn.AdaptiveMaxPool1d / nn.AdaptiveAvgPool1d：对于一维数据，适应性最大池化和平均池化。\n",
    "# nn.AdaptiveMaxPool2d / nn.AdaptiveAvgPool2d：对于二维数据，如图像，生成固定大小的输出，无论输入大小如何。\n",
    "# nn.AdaptiveMaxPool3d / nn.AdaptiveAvgPool3d：适用于三维数据，例如视频。\n",
    "# 2D Adaptive Max Pooling 示例\n",
    "x = torch.randn(1, 1, 8, 8)\n",
    "adaptive_pool = nn.AdaptiveMaxPool2d((4, 4))  # 输出固定大小为 4x4\n",
    "output = adaptive_pool(x)\n",
    "print(output.shape)  # 输出大小为 1x1x4x4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分数最大池化是一种特殊的池化方式，它允许窗口大小不是整数，这意味着池化的步幅可以是浮点数。它用于那些希望进行更细致下采样的场景。\n",
    "\n",
    "# nn.FractionalMaxPool2d：应用于二维图像数据，允许进行分数池化。\n",
    "# nn.FractionalMaxPool3d：应用于三维数据。\n",
    "# 2D Fractional Max Pooling 示例\n",
    "x = torch.randn(1, 1, 8, 8)\n",
    "fractional_pool = nn.FractionalMaxPool2d(kernel_size=3, output_size=(5, 5))\n",
    "output = fractional_pool(x)\n",
    "print(output.shape)  # 输出大小为 1x1x5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lp 池化是通过计算输入局部区域的 Lp 范数来进行池化的操作。通常，\n",
    "# p=2 对应二次范数，它用于聚合局部区域的信息。\n",
    "\n",
    "# nn.LPPool1d：应用于一维数据的 Lp 池化。\n",
    "# nn.LPPool2d：应用于二维数据的 Lp 池化。\n",
    "# nn.LPPool3d：应用于三维数据的 Lp 池化。\n",
    "# 2D Lp Pooling 示例\n",
    "x = torch.randn(1, 1, 8, 8)\n",
    "lp_pool = nn.LPPool2d(norm_type=2, kernel_size=2, stride=2)\n",
    "output = lp_pool(x)\n",
    "print(output.shape)  # 输出大小为 1x1x4x4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反池化（Unpooling）是一种与池化相反的操作，它将池化操作的结果还原回原始尺寸。反池化通常用于需要恢复原始尺寸的场景，例如在生成对抗网络（GAN）中。\n",
    "# 反池化除了需要结果以外，还得需要indices，因为池化操作会丢失位置信息，反池化需要知道每个池化窗口的位置，以便正确地恢复原始尺寸。\n",
    "# 反池化还原的数据会缺失除了最大值以外的所有信息，因为其余部分都用0填充了，所以反池化一般会和原数据一起使用，拼接起来。\n",
    "# 2D Max Unpooling 示例\n",
    "x = torch.randn(1, 1, 4, 4)\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "\n",
    "output, indices = maxpool(x)\n",
    "reconstructed = unpool(output, indices, output_size=x.size())\n",
    "print(reconstructed.shape)  # 输出大小为 1x1x4x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2., 1., 2., 3., 2.],\n",
      "         [5., 4., 5., 6., 5.]]])\n"
     ]
    }
   ],
   "source": [
    "# 反射填充使用输入边界的镜像来填充。\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.tensor([[[1, 2, 3], [4, 5, 6]]], dtype=torch.float32)  # 1D input\n",
    "pad_layer = nn.ReflectionPad1d(1)\n",
    "padded_tensor = pad_layer(input_tensor)\n",
    "print(padded_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 2., 3., 3.],\n",
      "         [4., 4., 5., 6., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "# 复制填充使用输入边界的值进行复制填充。\n",
    "pad_layer = nn.ReplicationPad1d(1)\n",
    "padded_tensor = pad_layer(input_tensor)\n",
    "print(padded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 1., 2., 3., 0.],\n",
      "         [0., 4., 5., 6., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# 零填充会在张量边界处填充零。\n",
    "pad_layer = nn.ZeroPad2d(1)\n",
    "padded_tensor = pad_layer(input_tensor)\n",
    "print(padded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10., 10., 10., 10., 10.],\n",
      "         [10.,  1.,  2.,  3., 10.],\n",
      "         [10.,  4.,  5.,  6., 10.],\n",
      "         [10., 10., 10., 10., 10.]]])\n"
     ]
    }
   ],
   "source": [
    "# 常数填充会在张量边界处填充指定的常数值。\n",
    "pad_layer = nn.ConstantPad2d(1, 10)  # 用10填充\n",
    "padded_tensor = pad_layer(input_tensor)\n",
    "print(padded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 1., 2., 3., 1.],\n",
      "         [6., 4., 5., 6., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "# 循环填充（也称为环绕填充）使用输入的边界来循环填充。\n",
    "pad_layer = nn.CircularPad1d(1)\n",
    "padded_tensor = pad_layer(input_tensor)\n",
    "print(padded_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各类激活函数在神经网络中扮演着不同的角色，根据任务和模型的需求选择合适的激活函数，可以提升模型的性能与训练效率。以下是 PyTorch 中常见激活函数及其特点与适用场景：\n",
    "\n",
    "### 1. **`nn.ELU`（Exponential Linear Unit）**\n",
    "- **特点**：ELU 在输入为负时指数衰减，正值则线性输出，避免了 ReLU 的死区问题（ReLU 在负区间输出为零）。\n",
    "- **适用场景**：在有些任务中，ELU 可能比 ReLU 收敛更快，适合深层神经网络。\n",
    "\n",
    "### 2. **`nn.Hardshrink`**\n",
    "- **特点**：Hardshrink 是一种稀疏激活函数，将小于阈值的输入截断为零。\n",
    "- **适用场景**：适用于需要稀疏输出的场景，比如特征选择或去噪。\n",
    "\n",
    "### 3. **`nn.Hardsigmoid`**\n",
    "- **特点**：简化的 Sigmoid 函数，计算量更少。输出值在 `[0, 1]` 之间，具有阶梯状的近似线性区域。\n",
    "- **适用场景**：适合在资源受限的应用中使用，或者当标准 Sigmoid 过于复杂时作为替代。\n",
    "\n",
    "### 4. **`nn.Hardtanh`**\n",
    "- **特点**：Tanh 的一种近似函数，输入在区间 `[-1, 1]` 之间线性输出，其余部分剪裁。\n",
    "- **适用场景**：和标准 Tanh 类似，适合需要处理带符号输入的任务，同时减少计算复杂度。\n",
    "\n",
    "### 5. **`nn.Hardswish`**\n",
    "- **特点**：近似 SiLU 的简化版本，带来与 SiLU 相似的特性，但计算更高效。\n",
    "- **适用场景**：适用于需要非线性特性的轻量级模型，尤其在移动设备上的应用。\n",
    "\n",
    "### 6. **`nn.LeakyReLU`**\n",
    "- **特点**：类似 ReLU，但允许负值以小的斜率通过，避免了 ReLU 死区问题（ReLU 在负值处输出零）。\n",
    "- **适用场景**：适合深度网络，特别是希望在负值区域保留一些梯度信息的场景。\n",
    "\n",
    "### 7. **`nn.LogSigmoid`**\n",
    "- **特点**：对 Sigmoid 进行对数变换，输出的范围是负数，梯度较为平滑。\n",
    "- **适用场景**：适合对数损失函数或涉及对数计算的场景。\n",
    "\n",
    "### 8. **`nn.MultiheadAttention`**\n",
    "- **特点**：实现多头注意力机制，允许模型从不同的表示空间关注输入序列中的不同部分。\n",
    "- **适用场景**：广泛用于自然语言处理中的 Transformer 模型和序列处理任务。\n",
    "\n",
    "### 9. **`nn.PReLU`（Parametric ReLU）**\n",
    "- **特点**：类似于 LeakyReLU，但负斜率是可学习的参数。\n",
    "- **适用场景**：适合需要在不同层或不同通道中学习不同激活模式的模型。\n",
    "\n",
    "### 10. **`nn.ReLU`（Rectified Linear Unit）**\n",
    "- **特点**：正值部分线性输出，负值部分输出为零。非常简单且计算效率高。\n",
    "- **适用场景**：广泛应用于几乎所有神经网络模型，适合大部分任务，尤其是图像处理任务。\n",
    "\n",
    "### 11. **`nn.ReLU6`**\n",
    "- **特点**：ReLU 的一种变体，输出限制在 `[0, 6]` 之间。\n",
    "- **适用场景**：用于限制输出范围的场景，例如在移动设备中使用的轻量级模型。\n",
    "\n",
    "### 12. **`nn.RReLU`（Randomized Leaky ReLU）**\n",
    "- **特点**：LeakyReLU 的随机版本，负斜率在训练时随机选择，在测试时固定。\n",
    "- **适用场景**：适合需要引入随机性以提高模型泛化能力的场景。\n",
    "\n",
    "### 13. **`nn.SELU`（Scaled Exponential Linear Unit）**\n",
    "- **特点**：SELU 是一种带有自归一化特性的激活函数，具有缩放指数衰减的特点。\n",
    "- **适用场景**：适合深度网络，并且不需要特别处理梯度消失的问题。\n",
    "\n",
    "### 14. **`nn.CELU`（Continuously Differentiable Exponential Linear Unit）**\n",
    "- **特点**：ELU 的一种改进版本，具有平滑的微分性。\n",
    "- **适用场景**：适合需要平滑梯度变化的任务。\n",
    "\n",
    "### 15. **`nn.GELU`（Gaussian Error Linear Unit）**\n",
    "- **特点**：使用高斯分布进行激活，具有平滑的非线性。\n",
    "- **适用场景**：适合 Transformer 等需要复杂非线性激活的网络。\n",
    "\n",
    "### 16. **`nn.Sigmoid`**\n",
    "- **特点**：标准的 Sigmoid 函数，输出值在 `[0, 1]` 之间，适合处理概率问题。\n",
    "- **适用场景**：常用于二分类任务的输出层。\n",
    "\n",
    "### 17. **`nn.SiLU`（Swish or Sigmoid Linear Unit）**\n",
    "- **特点**：Swish 激活函数，输出为 `x * sigmoid(x)`，具有平滑的非线性。\n",
    "- **适用场景**：适合需要精细非线性处理的任务，Google 的研究表明它在某些任务上优于 ReLU。\n",
    "\n",
    "### 18. **`nn.Mish`**\n",
    "- **特点**：Mish 函数具有平滑的非线性特性，被认为可以帮助梯度流动并提供更好的性能。\n",
    "- **适用场景**：在深层网络中可能会提供比 ReLU 更好的表现。\n",
    "\n",
    "### 19. **`nn.Softplus`**\n",
    "- **特点**：Softplus 是 ReLU 的平滑版本，输出为正值但没有硬性截断。\n",
    "- **适用场景**：用于需要平滑激活的场景，避免 ReLU 的硬性截断。\n",
    "\n",
    "### 20. **`nn.Softshrink`**\n",
    "- **特点**：Softshrink 在小于阈值时将输入值压缩到零。\n",
    "- **适用场景**：适合需要稀疏输出的场景，比如去噪或稀疏特征学习。\n",
    "\n",
    "### 21. **`nn.Softsign`**\n",
    "- **特点**：将输入缩放到 `[-1, 1]` 区间，梯度变化更平滑，减轻梯度消失问题。\n",
    "- **适用场景**：适合需要平滑、连续输出的任务。\n",
    "\n",
    "### 22. **`nn.Tanh`**\n",
    "- **特点**：双曲正切函数，输出值在 `[-1, 1]` 之间，适合处理带符号的输入。\n",
    "- **适用场景**：适用于大部分需要对负值敏感的任务。\n",
    "\n",
    "### 23. **`nn.Tanhshrink`**\n",
    "- **特点**：将输入减去其 Tanh 输出，使得小值被压缩到零。\n",
    "- **适用场景**：适合需要一定压缩效果但又不希望完全剪切的任务。\n",
    "\n",
    "### 24. **`nn.Threshold`**\n",
    "- **特点**：输入小于阈值时被压缩为一个固定值，大于阈值时保持不变。\n",
    "- **适用场景**：适合只需要简单门控效果的场景。\n",
    "\n",
    "### 25. **`nn.GLU`（Gated Linear Unit）**\n",
    "- **特点**：GLU 使用门控机制，对输入进行线性变换的同时保留一部分信息。\n",
    "- **适用场景**：用于需要门控机制的任务，如序列处理中的注意力机制。\n",
    "\n",
    "### 总结\n",
    "这些激活函数在不同任务和模型结构中发挥不同作用。比如，ReLU 及其变种适合大多数深度学习任务，Sigmoid 和 Softmax 常用于分类任务的输出层，而 SiLU、Mish 等较新的激活函数在一些特定任务上能提供更好的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非线性激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([-0.4032,  0.3346, -0.1698])\n",
      "Softmin Output: tensor([0.4405, 0.2106, 0.3488])\n"
     ]
    }
   ],
   "source": [
    "# nn.Softmin\n",
    "# Softmin 将输入张量转换为概率分布，输入越小，输出的概率越大。\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个随机输入张量\n",
    "x = torch.randn(3)\n",
    "print(\"Input:\", x)\n",
    "\n",
    "# 使用 Softmin 激活函数\n",
    "softmin = nn.Softmin(dim=0)\n",
    "output = softmin(x)\n",
    "print(\"Softmin Output:\", output)\n",
    "\n",
    "\n",
    "# Softmin 函数将输入的每个元素变换为非负数，且这些数的总和为 1，适用于需要把小值对应更大权重的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Output: tensor([0.2297, 0.4803, 0.2900])\n"
     ]
    }
   ],
   "source": [
    "# nn.Softmax\n",
    "# Softmax 是一种常见的激活函数，通常用于分类模型的输出层，将输入转换为概率分布，总和为 1。\n",
    "\n",
    "# 使用 Softmax 激活函数\n",
    "softmax = nn.Softmax(dim=0)\n",
    "output = softmax(x)\n",
    "print(\"Softmax Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax2d Output: tensor([[[[0.7692, 0.4978, 0.7621, 0.1117],\n",
      "          [0.0912, 0.0601, 0.1700, 0.3202],\n",
      "          [0.7793, 0.0620, 0.1259, 0.5856],\n",
      "          [0.1780, 0.2955, 0.6483, 0.3088]],\n",
      "\n",
      "         [[0.1960, 0.2612, 0.1600, 0.1357],\n",
      "          [0.5358, 0.6786, 0.4128, 0.2732],\n",
      "          [0.1536, 0.3405, 0.0772, 0.2953],\n",
      "          [0.6948, 0.3169, 0.1789, 0.4895]],\n",
      "\n",
      "         [[0.0348, 0.2410, 0.0779, 0.7526],\n",
      "          [0.3730, 0.2613, 0.4173, 0.4066],\n",
      "          [0.0671, 0.5975, 0.7970, 0.1192],\n",
      "          [0.1273, 0.3877, 0.1728, 0.2017]]],\n",
      "\n",
      "\n",
      "        [[[0.6234, 0.2767, 0.2991, 0.7504],\n",
      "          [0.2209, 0.4242, 0.0589, 0.3767],\n",
      "          [0.1096, 0.4359, 0.0438, 0.2790],\n",
      "          [0.1323, 0.2152, 0.6321, 0.3030]],\n",
      "\n",
      "         [[0.1173, 0.3958, 0.1302, 0.0986],\n",
      "          [0.5572, 0.4850, 0.6524, 0.1833],\n",
      "          [0.4225, 0.3180, 0.3152, 0.0541],\n",
      "          [0.6448, 0.3654, 0.0531, 0.2471]],\n",
      "\n",
      "         [[0.2593, 0.3275, 0.5708, 0.1510],\n",
      "          [0.2219, 0.0908, 0.2887, 0.4400],\n",
      "          [0.4679, 0.2461, 0.6410, 0.6669],\n",
      "          [0.2229, 0.4194, 0.3148, 0.4499]]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Softmax2d\n",
    "# Softmax2d 是专门用于 2D 张量（通常是图像）的 Softmax 函数，应用于图像的每个空间位置。\n",
    "# 创建一个 2D 张量，模拟图像的通道输出\n",
    "x_2d = torch.randn(2, 3, 4, 4)  # 形状为 (batch_size, channels, height, width)\n",
    "\n",
    "# 使用 Softmax2d 激活函数\n",
    "softmax2d = nn.Softmax2d()\n",
    "output_2d = softmax2d(x_2d)\n",
    "print(\"Softmax2d Output:\", output_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogSoftmax Output: tensor([-1.4711, -0.7333, -1.2377])\n"
     ]
    }
   ],
   "source": [
    "# nn.LogSoftmax\n",
    "# LogSoftmax 是 Softmax 函数的对数版本，常用于和交叉熵损失结合，因为它能更好地处理数值稳定性问题。\n",
    "# 使用 LogSoftmax 激活函数\n",
    "log_softmax = nn.LogSoftmax(dim=0)\n",
    "output = log_softmax(x)\n",
    "print(\"LogSoftmax Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaptiveLogSoftmaxWithLoss Output: tensor([-1.1073, -1.6581, -1.9083], grad_fn=<AddBackward0>)\n",
      "Loss: tensor(1.5579, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# nn.AdaptiveLogSoftmaxWithLoss\n",
    "# AdaptiveLogSoftmaxWithLoss 是一种高效的 Softmax 近似方法，适用于大词汇量的多分类任务，可以在保持计算效率的同时减少内存开销。\n",
    "\n",
    "# 创建一个具有 5 个类别的分类任务，并且假设有 10 个输入特征\n",
    "in_features = 10\n",
    "n_classes = 5\n",
    "\n",
    "# 输入数据和标签\n",
    "x = torch.randn(3, in_features)  # batch_size=3, input_features=10\n",
    "target = torch.randint(0, n_classes, (3,))\n",
    "\n",
    "# 定义 AdaptiveLogSoftmaxWithLoss\n",
    "adaptive_softmax = nn.AdaptiveLogSoftmaxWithLoss(in_features, n_classes, cutoffs=[2, 4])\n",
    "\n",
    "# 前向传播\n",
    "output = adaptive_softmax(x, target)\n",
    "print(\"AdaptiveLogSoftmaxWithLoss Output:\", output.output)\n",
    "print(\"Loss:\", output.loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在深度学习中，**归一化层**（Normalization Layers）起着至关重要的作用，能够加速训练、提高模型的性能并减少对初始化的敏感性。下面我们将讨论不同类型的归一化层，主要聚焦于它们的不同之处以及适用场景。\n",
    "\n",
    "### 1. **Batch Normalization (批量归一化)**\n",
    "- **`nn.BatchNorm1d`**: 应用于 2D 或 3D 输入，常用于处理序列数据或特征数据。\n",
    "- **`nn.BatchNorm2d`**: 应用于 4D 输入，通常用于卷积神经网络（CNN）的特征图。\n",
    "- **`nn.BatchNorm3d`**: 应用于 5D 输入，适合处理 3D 卷积（如视频数据）的模型。\n",
    "- **Lazy Versions**: \n",
    "  - **`nn.LazyBatchNorm1d`**: 懒惰初始化的 1D 批量归一化。\n",
    "  - **`nn.LazyBatchNorm2d`**: 懒惰初始化的 2D 批量归一化。\n",
    "  - **`nn.LazyBatchNorm3d`**: 懒惰初始化的 3D 批量归一化。\n",
    "\n",
    "**特点**:\n",
    "- **Batch Normalization** 是通过对每一批次的数据进行标准化，使其均值为 0，方差为 1。\n",
    "- 可以缓解梯度消失或爆炸问题，加速收敛。\n",
    "\n",
    "### 2. **Group Normalization (组归一化)**\n",
    "- **`nn.GroupNorm`**: 将特征分为多个组，每个组独立进行归一化。与批量归一化相比，它不依赖于批量大小，适用于小批量数据。\n",
    "\n",
    "**特点**:\n",
    "- 特别适合小批量（如小型图像分类）或者在分布不均的情况下。\n",
    "- 可以在不影响性能的前提下，适应不同的网络架构。\n",
    "\n",
    "### 3. **Instance Normalization (实例归一化)**\n",
    "- **`nn.InstanceNorm1d`**: 应用于 1D 输入。\n",
    "- **`nn.InstanceNorm2d`**: 应用于 2D 输入，通常用于图像生成任务。\n",
    "- **`nn.InstanceNorm3d`**: 应用于 3D 输入。\n",
    "\n",
    "**特点**:\n",
    "- 对每一个样本独立进行归一化，非常适合风格迁移、生成对抗网络（GAN）等任务。\n",
    "- 通过消除样本间的均值和方差的影响，使得模型更关注样本本身的特征。\n",
    "\n",
    "### 4. **Layer Normalization (层归一化)**\n",
    "- **`nn.LayerNorm`**: 对每个输入样本的特征进行归一化，通常用于 RNN 等序列模型中。\n",
    "\n",
    "**特点**:\n",
    "- 归一化是对每一个样本的所有特征进行处理，与批量归一化的不同之处在于，它不依赖于其他样本的特征。\n",
    "- 更适合于小批量的场景，因为它不会因批量大小而波动。\n",
    "\n",
    "### 5. **Local Response Normalization (局部响应归一化)**\n",
    "- **`nn.LocalResponseNorm`**: 主要用于卷积神经网络中的特征图，通过对邻域的响应进行归一化。\n",
    "\n",
    "**特点**:\n",
    "- 增强了模型的局部特征，常用于 AlexNet 等早期 CNN 架构中。\n",
    "\n",
    "### 6. **RMS Normalization (均方根归一化)**\n",
    "- **`nn.RMSNorm`**: 一种改进的层归一化方法，使用均方根（RMS）进行归一化。\n",
    "\n",
    "**特点**:\n",
    "- 与层归一化类似，但它使用 RMS 而不是均值和方差来进行归一化，可以在一些情况下提高稳定性和效果。\n",
    "\n",
    "### 总结\n",
    "- **Batch Normalization** 适合大批量的训练，通常用于 CNN，能有效加速训练。\n",
    "- **Group Normalization** 是处理小批量的好选择，适合不同的网络结构。\n",
    "- **Instance Normalization** 在风格迁移和 GAN 中效果显著。\n",
    "- **Layer Normalization** 适合 RNN 和其他依赖序列的任务。\n",
    "- **Local Response Normalization** 主要用于早期的 CNN 结构。\n",
    "- **RMS Normalization** 提供了一种新的归一化方式，适用于特定场景。\n",
    "\n",
    "选择适合的归一化层可以根据具体的模型结构、任务类型和数据特性来决定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d Output Shape: torch.Size([4, 4, 5, 5])\n",
      "GroupNorm Output Shape: torch.Size([4, 4, 5, 5])\n",
      "InstanceNorm2d Output Shape: torch.Size([4, 4, 5, 5])\n",
      "LayerNorm Output Shape: torch.Size([4, 4, 5, 5])\n",
      "LocalResponseNorm Output Shape: torch.Size([4, 4, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 输入示例\n",
    "batch_size = 4\n",
    "num_features = 4\n",
    "height = 5\n",
    "width = 5\n",
    "\n",
    "# Batch Normalization 示例\n",
    "# 对于 2D 输入，通常在 CNN 中使用\n",
    "batch_norm_2d = nn.BatchNorm2d(num_features)\n",
    "input_2d = torch.randn(batch_size, num_features, height, width)\n",
    "output_2d = batch_norm_2d(input_2d)\n",
    "\n",
    "# Group Normalization 示例\n",
    "group_norm = nn.GroupNorm(num_groups=2, num_channels=num_features)\n",
    "output_group_norm = group_norm(input_2d)\n",
    "\n",
    "# Instance Normalization 示例\n",
    "instance_norm_2d = nn.InstanceNorm2d(num_features)\n",
    "output_instance_norm = instance_norm_2d(input_2d)\n",
    "\n",
    "# Layer Normalization 示例\n",
    "layer_norm = nn.LayerNorm([num_features, height, width])\n",
    "output_layer_norm = layer_norm(input_2d)  # 保持 3D 输入\n",
    "\n",
    "# Local Response Normalization 示例\n",
    "local_response_norm = nn.LocalResponseNorm(size=5)\n",
    "output_local_response_norm = local_response_norm(input_2d)\n",
    "\n",
    "# RMS Normalization 示例\n",
    "# rms_norm = nn.RMSNorm(num_features)\n",
    "# output_rms_norm = rms_norm(input_2d.view(batch_size, -1))\n",
    "\n",
    "# 打印输出的形状以验证\n",
    "print(\"BatchNorm2d Output Shape:\", output_2d.shape)\n",
    "print(\"GroupNorm Output Shape:\", output_group_norm.shape)\n",
    "print(\"InstanceNorm2d Output Shape:\", output_instance_norm.shape)\n",
    "print(\"LayerNorm Output Shape:\", output_layer_norm.shape)\n",
    "print(\"LocalResponseNorm Output Shape:\", output_local_response_norm.shape)\n",
    "# print(\"RMSNorm Output Shape:\", output_rms_norm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Layers\n",
    "\n",
    "RNN层用于简单的序列数据处理。\n",
    "\n",
    "LSTM层更复杂，能有效处理长期依赖关系。\n",
    "\n",
    "GRU层比LSTM高效且复杂度低，适合许多任务。\n",
    "\n",
    "RNNCell、LSTMCell和GRUCell提供对状态管理的精细控制，这对于自定义架构非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size=10, hidden_size=20, num_layers=2, nonlinearity='tanh', batch_first=True)\n",
    "\n",
    "lstm = nn.LSTM(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "\n",
    "gru = nn.GRU(input_size=10, hidden_size=20, num_layers=2, batch_first=True)\n",
    "\n",
    "\n",
    "input_tensor = torch.randn(batch_size, 10)\n",
    "\n",
    "# RNNCell 示例\n",
    "rnn_cell = nn.RNNCell(input_size=10, hidden_size=20)\n",
    "hidden = torch.zeros(batch_size, 20)\n",
    "output = rnn_cell(input_tensor, hidden)\n",
    "\n",
    "\n",
    "\n",
    "# LSTMCell 示例\n",
    "lstm_cell = nn.LSTMCell(input_size=10, hidden_size=20)\n",
    "hidden, cell = (torch.zeros(batch_size, 20), torch.zeros(batch_size, 20))\n",
    "output = lstm_cell(input_tensor, (hidden, cell))\n",
    "\n",
    "# GRUCell 示例\n",
    "gru_cell = nn.GRUCell(input_size=10, hidden_size=20)\n",
    "hidden = torch.zeros(batch_size, 20)\n",
    "output = gru_cell(input_tensor, hidden)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\epiph\\.conda\\envs\\torchproject\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 超参数\n",
    "d_model = 512  # 模型维度\n",
    "nhead = 8      # 注意力头数\n",
    "num_encoder_layers = 6  # 编码器层数\n",
    "num_decoder_layers = 6  # 解码器层数\n",
    "dim_feedforward = 2048   # 前馈网络的维度\n",
    "dropout = 0.1            # dropout率\n",
    "\n",
    "# 构建Transformer模型\n",
    "transformer = nn.Transformer(d_model=d_model, nhead=nhead,\n",
    "                              num_encoder_layers=num_encoder_layers,\n",
    "                              num_decoder_layers=num_decoder_layers,\n",
    "                              dim_feedforward=dim_feedforward,\n",
    "                              dropout=dropout)\n",
    "\n",
    "# 输入张量（假设是批次大小为10，序列长度为20，特征维度为512）\n",
    "src = torch.randn(20, 10, d_model)  # 源序列\n",
    "tgt = torch.randn(20, 10, d_model)  # 目标序列\n",
    "\n",
    "# 前向传播\n",
    "output = transformer(src, tgt)\n",
    "\n",
    "# 输出维度： (目标序列长度, 批次大小, 特征维度)\n",
    "print(output.shape)  # 应该输出torch.Size([20, 10, 512])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# nn.Identity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "identity_layer = nn.Identity()\n",
    "input_data = torch.randn(5, 3)\n",
    "output = identity_layer(input_data)\n",
    "\n",
    "print(output.shape)  # 输出: torch.Size([5, 3])，与输入相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear\n",
    "linear_layer = nn.Linear(in_features=3, out_features=2)\n",
    "input_data = torch.randn(5, 3)\n",
    "output = linear_layer(input_data)\n",
    "\n",
    "print(output.shape)  # 输出: torch.Size([5, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# nn.Bilinear\n",
    "bilinear_layer = nn.Bilinear(in1_features=4, in2_features=5, out_features=2)\n",
    "input1 = torch.randn(3, 4)  # 第一个输入，大小为 (batch_size, in1_features)\n",
    "input2 = torch.randn(3, 5)  # 第二个输入，大小为 (batch_size, in2_features)\n",
    "output = bilinear_layer(input1, input2)\n",
    "\n",
    "print(output.shape)  # 输出: torch.Size([3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\epiph\\.conda\\envs\\torchproject\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# nn.LazyLinear 是 nn.Linear 的延迟版本，in_features 会在第一次前向传播时推断出来，这对于构建动态网络结构非常有用。\n",
    "lazy_linear_layer = nn.LazyLinear(out_features=2)  # 不需要指定 in_features\n",
    "input_data = torch.randn(3, 4)  # 输入数据\n",
    "output = lazy_linear_layer(input_data)\n",
    "\n",
    "print(output.shape)  # 输出: torch.Size([3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DropOut Layers\n",
    "Dropout对整个通道进行置零的操作，如果是Dropout，则相当于每一个通道都是一个0维的数，就是将常数置为0，后面2d和3d都是将整个通道置为0，包括里面的所有维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5829,  1.5258,  3.7213, -2.9059],\n",
      "        [-0.0000,  0.0000,  2.1286, -0.2770],\n",
      "        [-3.7058, -1.2279,  0.4626, -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Dropout\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "dropout_layer = nn.Dropout(p=0.5)\n",
    "input_data = torch.randn(3, 4)\n",
    "output = dropout_layer(input_data)\n",
    "\n",
    "print(output)  # 部分元素将被置为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0000,  0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "          -0.0000, -0.0000,  0.0000],\n",
      "         [-3.2586, -0.0196,  3.3419,  1.0078,  0.1490,  0.6181, -1.5868,\n",
      "          -0.0281, -0.4238,  1.6973],\n",
      "         [-0.6080,  0.3559, -1.3751, -1.5537, -3.0022, -2.9056, -0.9778,\n",
      "           1.5977,  0.7983,  2.3488],\n",
      "         [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
      "          -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[ 1.0811, -2.7068,  0.2929, -1.0467, -2.0723, -0.5709, -0.2004,\n",
      "          -2.5476, -2.5667, -0.0902],\n",
      "         [-1.1177,  2.1965, -2.8573,  2.2241,  2.6370,  2.4197,  1.7120,\n",
      "          -0.7738,  2.0432, -2.0385],\n",
      "         [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "           0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "          -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-1.0414, -0.3292, -1.6101, -2.5687,  3.1574, -1.1343,  0.9455,\n",
      "           0.4257, -1.7143,  0.4190],\n",
      "         [-0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
      "          -0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000,\n",
      "          -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "          -0.0000, -0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Dropout1d\n",
    "dropout1d_layer = nn.Dropout1d(p=0.5)\n",
    "input_data = torch.randn(3, 4, 10)  # 3 个样本，4 个通道，10 个特征\n",
    "output = dropout1d_layer(input_data)\n",
    "\n",
    "print(output)  # 整个通道将被置为 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.3693,  2.7405, -2.1436,  ..., -2.3167, -0.9858, -0.2188],\n",
      "          [-0.7458,  0.6100, -3.6795,  ..., -0.4737, -3.3482,  0.8720],\n",
      "          [ 2.4779,  2.2467,  2.4052,  ..., -0.1706,  0.5075, -0.2248],\n",
      "          ...,\n",
      "          [ 1.3884,  3.4897, -1.5378,  ...,  0.7729, -1.1729, -0.6638],\n",
      "          [-0.7910, -1.3153,  1.1112,  ...,  0.6105,  0.1698,  0.4469],\n",
      "          [-0.1943, -1.8806,  2.4401,  ...,  1.1114, -1.8727, -1.7596]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          ...,\n",
      "          [ 0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          ...,\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2354,  2.3769,  0.7102,  ..., -0.1139, -0.3260,  1.9894],\n",
      "          [ 1.3857, -0.1875,  0.4051,  ..., -0.6552, -2.1865, -2.1896],\n",
      "          [ 1.7789,  0.7985, -0.5838,  ..., -1.6840, -1.7629,  0.4095],\n",
      "          ...,\n",
      "          [ 3.8785,  1.2916, -0.3795,  ...,  1.2863, -1.6780,  0.0481],\n",
      "          [ 2.2296, -4.6568, -0.2511,  ..., -2.0189,  0.6588,  3.3882],\n",
      "          [ 0.7100, -3.3986, -0.5469,  ...,  0.7744, -1.0896,  1.5206]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "          ...,\n",
      "          [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "          ...,\n",
      "          [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 1.6244,  2.8698,  0.2156,  ...,  2.3306, -4.0531, -3.9837],\n",
      "          [ 0.4802,  2.8704, -0.3658,  ...,  3.4619,  2.8437,  0.0536],\n",
      "          [-0.0843,  1.6964,  2.7052,  ..., -3.1170, -3.6362,  0.4094],\n",
      "          ...,\n",
      "          [-1.5978, -0.0131, -0.5962,  ..., -0.1868,  1.0773, -3.4347],\n",
      "          [-1.1403, -0.6446, -0.0195,  ..., -0.0753,  2.0143,  0.3928],\n",
      "          [-1.6466,  0.9024,  0.1794,  ..., -0.4068, -0.6524,  1.6768]]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Dropout2d\n",
    "dropout2d_layer = nn.Dropout2d(p=0.5)\n",
    "input_data = torch.randn(3, 4, 10, 10)  # 3 个样本，4 个通道，10x10 大小的特征图\n",
    "output = dropout2d_layer(input_data)\n",
    "\n",
    "print(output)  # 整个通道将被置为 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[-6.7597e-02, -2.9250e+00, -2.3700e+00,  ..., -3.7730e+00,\n",
      "            -4.3376e+00, -1.4762e+00],\n",
      "           [ 1.4143e-01,  1.9652e+00, -4.8575e+00,  ...,  9.8192e-01,\n",
      "             2.1656e-01,  3.2417e+00],\n",
      "           [ 3.6589e+00,  2.8928e-01,  5.1742e+00,  ..., -7.0305e-01,\n",
      "            -9.0443e-01,  1.2187e+00],\n",
      "           ...,\n",
      "           [ 1.7021e+00,  1.9935e+00, -7.4456e-01,  ..., -1.5689e+00,\n",
      "             3.2808e+00,  2.0391e+00],\n",
      "           [-7.4573e-01,  7.1924e-01, -2.5334e+00,  ...,  2.5452e+00,\n",
      "             9.2589e-01,  5.3044e-01],\n",
      "           [-1.7676e+00,  6.8841e-01,  8.6134e-01,  ...,  1.1133e+00,\n",
      "            -1.9554e+00, -9.4730e-02]],\n",
      "\n",
      "          [[-2.3544e+00,  5.2118e-01,  5.0842e-02,  ...,  1.2093e+00,\n",
      "             1.4783e-01, -2.6261e+00],\n",
      "           [-1.0022e+00,  1.1727e+00,  4.6162e-01,  ...,  2.2009e+00,\n",
      "            -9.4969e-01, -1.6582e+00],\n",
      "           [-2.7202e-01,  5.5333e-02,  1.7157e+00,  ..., -1.3081e+00,\n",
      "            -1.5147e+00, -1.4987e+00],\n",
      "           ...,\n",
      "           [ 9.5039e-01, -8.6036e-01, -1.2625e+00,  ..., -3.5203e-01,\n",
      "             2.3613e-01, -2.1447e+00],\n",
      "           [-4.8963e+00, -2.3905e+00,  3.7598e+00,  ...,  3.0680e+00,\n",
      "            -1.6131e-01,  1.6869e+00],\n",
      "           [ 2.7280e-01,  1.4336e+00,  5.6227e-01,  ..., -1.3914e+00,\n",
      "             2.3030e+00,  2.2840e+00]],\n",
      "\n",
      "          [[-1.7304e+00,  3.4928e+00, -2.1051e+00,  ..., -9.9962e-01,\n",
      "             1.7064e+00, -5.1081e-01],\n",
      "           [-5.6737e-01, -1.5683e+00,  6.6060e-01,  ..., -2.1830e+00,\n",
      "             1.6025e+00, -7.1230e-01],\n",
      "           [-2.0633e+00,  1.6947e+00, -2.6245e+00,  ...,  1.5854e+00,\n",
      "            -4.4322e-01, -1.4343e+00],\n",
      "           ...,\n",
      "           [ 2.7925e-01,  4.3133e-01, -2.7305e-01,  ...,  6.3846e-01,\n",
      "             2.4329e+00,  2.7733e+00],\n",
      "           [-2.7315e+00, -6.1134e-01, -1.0673e+00,  ..., -4.0169e+00,\n",
      "             2.7769e+00, -2.3104e+00],\n",
      "           [-5.1026e-01,  1.8272e+00,  1.0472e+00,  ..., -2.7731e+00,\n",
      "            -1.3851e+00, -1.1531e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.6076e-01,  4.2603e+00, -2.5132e+00,  ..., -1.9350e-01,\n",
      "             1.2822e+00,  1.8500e+00],\n",
      "           [ 4.8969e-01, -3.1073e+00,  2.8203e-01,  ...,  2.5384e-02,\n",
      "             1.7762e+00, -1.2133e+00],\n",
      "           [ 2.0490e-01,  5.2864e-01,  2.1903e+00,  ..., -4.7799e+00,\n",
      "            -2.1244e+00,  2.0266e+00],\n",
      "           ...,\n",
      "           [-2.3824e+00,  1.5896e+00,  5.0432e-01,  ..., -8.8241e-01,\n",
      "             2.2874e-02, -4.7012e+00],\n",
      "           [-1.7346e+00,  1.7060e-01,  1.9194e+00,  ...,  1.2866e+00,\n",
      "             6.5116e-01,  3.3794e+00],\n",
      "           [-2.5672e+00,  3.8765e-01, -1.5292e+00,  ..., -4.6078e+00,\n",
      "            -3.1367e+00,  1.8516e+00]],\n",
      "\n",
      "          [[-3.0591e+00, -9.2505e-02, -1.0246e+00,  ..., -1.3070e+00,\n",
      "             2.6274e+00, -4.4021e+00],\n",
      "           [ 2.1153e+00,  1.7015e+00, -3.2910e+00,  ..., -1.2046e+00,\n",
      "             2.3903e-01, -1.6078e-01],\n",
      "           [-1.1420e+00, -1.1178e+00,  1.3639e+00,  ..., -1.2382e+00,\n",
      "            -3.8260e+00, -2.2270e+00],\n",
      "           ...,\n",
      "           [ 4.6716e-01,  1.8857e+00,  2.2398e+00,  ..., -3.3133e+00,\n",
      "            -2.5678e-01, -2.0155e-01],\n",
      "           [ 2.0254e+00,  6.5043e-02, -9.4702e-01,  ...,  4.6686e+00,\n",
      "            -1.6552e-01, -2.9131e+00],\n",
      "           [-1.7570e+00, -3.7593e-01,  1.5253e+00,  ..., -1.1850e+00,\n",
      "             1.3204e-01,  1.6834e+00]],\n",
      "\n",
      "          [[ 1.7798e+00, -1.8827e+00, -1.9492e+00,  ...,  4.8240e-01,\n",
      "            -1.5416e+00, -2.7362e-01],\n",
      "           [ 1.0267e-01,  2.7751e+00,  2.6929e-01,  ...,  2.6031e+00,\n",
      "             1.2110e+00, -2.3527e+00],\n",
      "           [ 3.0811e+00, -1.0654e+00,  7.7291e-01,  ...,  9.7233e-01,\n",
      "            -2.6722e+00,  2.2830e+00],\n",
      "           ...,\n",
      "           [-1.6696e+00, -8.1951e-01,  2.8712e+00,  ...,  2.1124e+00,\n",
      "             4.7466e-01,  2.7098e+00],\n",
      "           [ 1.7850e+00,  1.0240e+00,  1.0330e+00,  ..., -3.3293e+00,\n",
      "             2.6877e+00,  5.9437e-01],\n",
      "           [-1.9087e+00, -5.9430e-01, -2.5525e+00,  ..., -1.9988e+00,\n",
      "            -6.7147e-01, -4.3633e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[-1.0717e+00,  2.9215e+00,  2.1829e+00,  ...,  2.0878e+00,\n",
      "             2.6686e+00,  4.2302e+00],\n",
      "           [-5.3947e-01, -3.7294e+00,  8.2592e-01,  ..., -1.0755e+00,\n",
      "             3.4442e-01,  3.3901e+00],\n",
      "           [-4.3947e-01,  3.1478e+00,  2.4384e-01,  ...,  6.1638e-01,\n",
      "             1.0366e+00,  1.7395e-02],\n",
      "           ...,\n",
      "           [ 2.8387e+00,  8.4135e-01, -5.4441e-01,  ...,  4.9587e-01,\n",
      "            -1.9891e+00, -9.9297e-01],\n",
      "           [-3.4220e+00,  5.5679e-01, -1.6102e-01,  ...,  1.4565e+00,\n",
      "             5.8640e-01,  3.6803e+00],\n",
      "           [-3.2327e+00, -2.1367e+00, -4.0471e-01,  ...,  2.7478e+00,\n",
      "             8.2789e-01,  5.8964e-01]],\n",
      "\n",
      "          [[ 1.0492e+00, -3.2514e-01,  5.6133e-02,  ..., -3.4095e+00,\n",
      "             1.0087e+00,  4.8570e+00],\n",
      "           [ 1.6171e-01,  1.4615e-01, -2.7218e+00,  ..., -5.4180e-01,\n",
      "            -1.5197e+00,  2.3908e+00],\n",
      "           [-2.0930e+00,  3.6255e+00, -1.4622e+00,  ...,  6.4944e-01,\n",
      "            -2.8929e-01, -8.2393e-01],\n",
      "           ...,\n",
      "           [-3.3444e+00,  7.4845e-01,  5.4533e+00,  ...,  3.1469e-01,\n",
      "            -6.5373e-01, -1.8619e+00],\n",
      "           [-5.6699e-01,  3.7803e+00, -8.7494e-01,  ...,  1.8224e-01,\n",
      "             1.3167e+00,  1.6665e+00],\n",
      "           [ 6.1469e-01,  1.9757e+00, -2.0905e+00,  ..., -3.6138e+00,\n",
      "             5.8754e-01,  2.4363e+00]],\n",
      "\n",
      "          [[-2.6817e+00,  3.2193e+00, -6.4711e-01,  ..., -2.1032e+00,\n",
      "             1.3225e+00, -3.3983e+00],\n",
      "           [ 1.1926e+00,  7.3763e-01, -5.5144e-02,  ..., -9.4206e-01,\n",
      "            -1.4448e+00,  4.1846e+00],\n",
      "           [ 4.5188e-02, -1.8498e+00,  1.4362e+00,  ..., -1.4245e+00,\n",
      "            -6.9874e-01, -2.2650e+00],\n",
      "           ...,\n",
      "           [-2.2814e+00, -1.5182e+00, -2.7304e+00,  ..., -2.1871e+00,\n",
      "             9.1878e-01,  8.5521e-01],\n",
      "           [-1.2380e+00, -2.2803e+00, -5.5143e-01,  ...,  1.6223e+00,\n",
      "            -8.1093e-01,  1.0312e+00],\n",
      "           [ 2.4902e-01, -1.7624e+00, -2.4315e+00,  ...,  3.9671e+00,\n",
      "             1.8069e+00,  8.1936e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 3.2619e+00,  1.2596e+00,  1.5558e+00,  ...,  2.4377e+00,\n",
      "             4.1722e+00, -1.5832e+00],\n",
      "           [-1.2636e+00, -1.2465e+00, -1.3796e+00,  ..., -1.7063e+00,\n",
      "             3.5505e+00, -1.4039e+00],\n",
      "           [-1.4669e+00, -1.8464e+00,  4.2957e-02,  ...,  3.6828e-01,\n",
      "            -2.9033e+00,  3.0687e+00],\n",
      "           ...,\n",
      "           [-2.7379e+00,  2.3925e+00,  8.8074e-01,  ...,  9.9727e-01,\n",
      "             2.3838e+00, -5.7300e-01],\n",
      "           [-2.2166e+00,  2.6931e+00, -2.4569e-01,  ..., -1.5788e+00,\n",
      "             6.2142e-03,  4.0415e+00],\n",
      "           [ 1.1380e+00,  6.3630e-01,  2.0380e+00,  ...,  8.6730e-01,\n",
      "            -1.7438e+00, -1.0809e+00]],\n",
      "\n",
      "          [[-3.9767e-02, -1.4955e+00,  3.0672e-01,  ...,  8.3356e-01,\n",
      "            -1.1462e+00,  2.8059e+00],\n",
      "           [ 3.7233e+00, -2.3601e+00,  2.4517e+00,  ...,  2.9369e-01,\n",
      "            -1.7979e-01, -7.2685e-01],\n",
      "           [ 3.2004e-02,  2.0709e-01, -3.4228e+00,  ..., -7.8608e-01,\n",
      "             1.9133e+00,  1.0179e+00],\n",
      "           ...,\n",
      "           [ 2.6563e+00,  8.4297e-01,  1.0001e+00,  ...,  1.8505e+00,\n",
      "             5.6044e-01, -1.0351e+00],\n",
      "           [ 1.6362e+00, -5.8974e-01, -1.2374e+00,  ..., -8.8460e-01,\n",
      "             3.6439e+00,  1.0198e+00],\n",
      "           [-1.0909e+00, -3.5619e-01,  1.7306e+00,  ...,  5.8986e-01,\n",
      "             2.3399e-01, -8.9410e-01]],\n",
      "\n",
      "          [[-2.4151e+00,  9.7930e-01,  1.8180e+00,  ..., -1.2887e+00,\n",
      "             1.7110e+00,  6.0301e-01],\n",
      "           [-1.4714e+00, -1.5971e+00, -1.8058e+00,  ...,  2.6917e+00,\n",
      "             1.6901e+00,  1.7257e+00],\n",
      "           [-2.6019e+00,  2.5184e-01,  9.0391e-01,  ...,  4.8586e+00,\n",
      "             2.6424e+00,  1.7560e+00],\n",
      "           ...,\n",
      "           [-9.7957e-01, -1.4914e+00, -1.3284e+00,  ..., -1.2624e+00,\n",
      "             8.6975e-01,  1.2204e+00],\n",
      "           [ 4.9023e-01,  9.3790e-01,  2.2666e+00,  ...,  1.7727e+00,\n",
      "             6.2414e-02, -3.6287e+00],\n",
      "           [ 1.8462e+00, -3.7703e+00,  7.9756e-01,  ...,  6.4650e-01,\n",
      "            -4.8884e-01,  2.6837e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 3.4085e+00, -9.3034e-02, -6.9829e-01,  ...,  4.2553e-02,\n",
      "             1.1515e+00, -1.5366e-01],\n",
      "           [-3.1324e+00, -1.4706e+00, -3.3134e+00,  ..., -7.1609e-01,\n",
      "             1.1520e+00, -4.3242e-01],\n",
      "           [ 1.6354e+00,  1.4172e+00, -3.0746e-02,  ...,  1.1028e+00,\n",
      "             1.0074e+00,  1.7329e+00],\n",
      "           ...,\n",
      "           [ 1.0300e+00, -1.2918e+00,  4.2856e+00,  ...,  1.5681e-01,\n",
      "             2.0257e+00, -7.7600e-02],\n",
      "           [-1.1740e+00,  5.5931e-01, -8.4222e-01,  ...,  2.1055e+00,\n",
      "            -1.6925e+00,  1.0416e+00],\n",
      "           [-1.7500e-01, -5.9282e-01, -4.8359e-01,  ..., -6.6918e-01,\n",
      "             7.3672e-01,  1.5673e+00]],\n",
      "\n",
      "          [[-5.9451e-01, -1.4847e+00,  1.5457e+00,  ...,  2.7171e+00,\n",
      "             2.8159e+00,  9.9422e-01],\n",
      "           [ 8.7337e-01,  4.8951e+00,  1.7033e+00,  ..., -2.1591e+00,\n",
      "             5.5824e-01,  1.1290e-01],\n",
      "           [-3.9688e-01,  8.5529e-01, -3.7677e-01,  ..., -1.3204e-01,\n",
      "             1.1736e+00, -6.4722e-01],\n",
      "           ...,\n",
      "           [-8.9966e-01, -1.8777e+00, -7.2785e-02,  ...,  5.1493e-01,\n",
      "             1.1446e+00,  2.8593e+00],\n",
      "           [ 1.3930e+00,  6.3816e-01,  1.5343e+00,  ...,  1.5170e+00,\n",
      "            -2.4059e+00,  2.0354e+00],\n",
      "           [ 6.5608e-01, -2.5039e+00,  4.2152e+00,  ..., -1.9753e+00,\n",
      "             1.4117e+00, -1.6218e+00]],\n",
      "\n",
      "          [[-1.8100e+00, -6.1632e-01, -2.0129e+00,  ...,  2.8424e+00,\n",
      "             1.7050e+00,  1.2233e+00],\n",
      "           [-3.8339e+00,  3.6822e+00, -9.7165e-01,  ..., -9.9984e-02,\n",
      "            -1.4997e+00, -6.9895e-01],\n",
      "           [ 2.3543e+00, -4.8404e-01,  3.6482e-01,  ..., -1.7107e+00,\n",
      "             1.7177e+00,  1.9631e+00],\n",
      "           ...,\n",
      "           [ 3.8950e+00, -1.8543e+00, -1.7562e-01,  ...,  8.5221e-02,\n",
      "            -2.4792e-01,  8.0678e-01],\n",
      "           [ 1.3337e+00, -1.4678e+00,  3.2719e+00,  ..., -4.3691e-01,\n",
      "            -1.3260e+00,  4.5432e-02],\n",
      "           [-3.9923e+00, -2.8719e+00, -1.6829e+00,  ..., -4.6382e-01,\n",
      "             4.3998e+00, -8.1180e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.9441e+00,  5.0575e-01, -1.0849e+00,  ..., -2.5930e-01,\n",
      "            -3.5409e+00,  5.4474e-01],\n",
      "           [-4.1748e+00, -1.1250e+00,  1.9003e-01,  ..., -9.4710e-01,\n",
      "            -8.1341e-01, -2.9076e+00],\n",
      "           [-1.2613e+00, -2.0981e+00,  1.0438e-01,  ...,  4.7033e+00,\n",
      "            -1.4444e+00,  7.2018e-01],\n",
      "           ...,\n",
      "           [ 2.3274e+00, -1.5067e+00,  1.2350e-01,  ...,  1.1997e+00,\n",
      "            -1.3371e+00, -1.1687e+00],\n",
      "           [-3.9453e-02, -1.8514e+00,  7.2943e-01,  ...,  3.4842e-01,\n",
      "            -2.0447e+00,  1.3628e+00],\n",
      "           [ 1.3554e+00, -3.7179e+00, -1.5253e+00,  ..., -3.0550e+00,\n",
      "            -2.2842e+00, -5.9234e-03]],\n",
      "\n",
      "          [[-1.4165e+00, -2.7598e+00, -2.0661e+00,  ..., -7.2967e-01,\n",
      "             1.4261e+00, -5.8065e+00],\n",
      "           [-1.0787e+00, -2.4603e+00,  1.3824e+00,  ...,  2.7446e+00,\n",
      "            -1.3710e+00,  3.2545e-01],\n",
      "           [-4.9979e-01, -2.2772e+00, -9.4946e-01,  ..., -2.6530e+00,\n",
      "            -3.0926e+00, -1.9334e+00],\n",
      "           ...,\n",
      "           [-8.6414e-01,  5.7492e-01,  3.4255e+00,  ...,  1.7756e-01,\n",
      "             1.9046e+00,  8.7762e-01],\n",
      "           [-8.8781e-01,  3.5906e-01, -1.0754e+00,  ..., -2.5815e+00,\n",
      "             1.0022e+00, -3.1531e+00],\n",
      "           [ 2.8649e+00, -5.7843e-01, -2.2778e+00,  ...,  3.6641e-01,\n",
      "             1.8490e-01,  1.0613e+00]],\n",
      "\n",
      "          [[-6.6760e-01, -6.8310e-01,  1.0904e+00,  ..., -3.2975e-01,\n",
      "            -2.1096e+00, -2.9025e+00],\n",
      "           [-6.0490e-01, -1.1018e+00, -4.5732e+00,  ...,  3.6688e-01,\n",
      "            -6.1254e-02, -1.7843e+00],\n",
      "           [-3.2808e-01, -3.3072e+00, -3.4023e+00,  ..., -6.1320e+00,\n",
      "            -3.2990e+00,  3.0879e+00],\n",
      "           ...,\n",
      "           [ 1.8325e-01,  1.5718e+00,  7.7729e+00,  ..., -8.5586e-01,\n",
      "            -1.1995e+00,  3.3542e+00],\n",
      "           [-1.6526e+00, -2.5666e+00, -3.1307e+00,  ...,  2.7482e+00,\n",
      "            -2.6711e+00,  3.7008e-01],\n",
      "           [-6.4277e+00,  7.8868e-01, -7.4480e-01,  ..., -2.7344e+00,\n",
      "            -9.0109e-01,  9.1824e-01]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "          [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "          [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00],\n",
      "           ...,\n",
      "           [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "             0.0000e+00, -0.0000e+00],\n",
      "           [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "            -0.0000e+00,  0.0000e+00],\n",
      "           [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "            -0.0000e+00, -0.0000e+00]]],\n",
      "\n",
      "\n",
      "         [[[-1.2583e+00, -3.7615e-01,  7.4733e-01,  ..., -2.2987e+00,\n",
      "             1.2808e+00,  4.2286e-01],\n",
      "           [-5.0310e-01, -3.0429e+00, -1.0165e+00,  ...,  1.2216e+00,\n",
      "            -9.4397e-01,  2.5378e+00],\n",
      "           [-2.1405e+00,  1.7095e+00,  1.0842e+00,  ..., -4.3250e+00,\n",
      "             3.5443e+00, -1.4414e+00],\n",
      "           ...,\n",
      "           [ 6.9818e-01, -2.0394e+00,  5.3045e+00,  ...,  1.8099e+00,\n",
      "            -3.3571e+00, -1.4821e-01],\n",
      "           [-1.5079e-01, -4.0884e+00,  2.3295e+00,  ...,  2.1674e+00,\n",
      "             1.0701e+00,  6.8785e-01],\n",
      "           [ 2.6620e+00,  3.1466e+00,  4.2829e-02,  ...,  2.1894e+00,\n",
      "             3.0058e-01,  4.8243e-01]],\n",
      "\n",
      "          [[-4.3302e+00, -1.4962e+00,  1.6442e+00,  ..., -2.8058e+00,\n",
      "             1.8067e+00,  3.0038e+00],\n",
      "           [ 3.8887e-01, -1.3436e-01, -5.9669e-01,  ..., -1.7883e+00,\n",
      "            -2.8592e+00,  4.3372e+00],\n",
      "           [ 3.3513e-01,  4.1322e+00,  9.7394e-01,  ..., -2.1323e+00,\n",
      "            -4.4895e-01,  2.1444e+00],\n",
      "           ...,\n",
      "           [-3.4594e+00, -1.5427e+00, -2.2046e+00,  ..., -1.7701e+00,\n",
      "             1.1284e+00,  1.0755e+00],\n",
      "           [-1.8992e+00,  1.4281e+00, -4.2691e+00,  ..., -3.3474e+00,\n",
      "             2.9412e+00,  2.1964e+00],\n",
      "           [ 3.0324e+00, -1.0750e+00,  1.4791e+00,  ..., -1.3467e+00,\n",
      "            -2.4949e-01, -1.0676e+00]],\n",
      "\n",
      "          [[-6.9534e-01, -1.0993e+00,  3.4936e-02,  ...,  1.2907e+00,\n",
      "             2.4542e+00,  3.2257e-01],\n",
      "           [-1.1495e-01,  9.9176e-02, -1.0377e+00,  ..., -1.2563e+00,\n",
      "            -6.2615e-02,  2.3815e+00],\n",
      "           [-8.4480e-01,  7.3990e-01,  2.5183e-01,  ...,  2.5469e-01,\n",
      "            -9.5329e-01, -8.6490e-01],\n",
      "           ...,\n",
      "           [-3.7207e-01, -9.6952e-01,  1.4867e+00,  ...,  1.2162e-02,\n",
      "             2.0660e+00, -2.8338e+00],\n",
      "           [-2.5581e+00, -2.9030e+00,  4.7845e-02,  ..., -5.7037e-03,\n",
      "            -2.3610e+00,  2.4796e+00],\n",
      "           [ 5.8708e-01,  1.0971e+00,  1.5934e+00,  ...,  8.7742e-01,\n",
      "             2.1773e+00,  9.8735e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.2817e+00,  2.5555e+00,  1.9727e+00,  ..., -3.0890e-01,\n",
      "            -2.2204e-02, -2.7248e+00],\n",
      "           [ 3.7973e-01,  1.1470e+00, -1.0413e-01,  ...,  4.3307e-01,\n",
      "             7.6618e-01,  1.7786e+00],\n",
      "           [ 1.9011e+00,  2.5437e+00, -1.3245e+00,  ..., -8.0529e-01,\n",
      "            -9.6623e-01, -2.6943e+00],\n",
      "           ...,\n",
      "           [-3.3370e+00,  1.8225e+00,  1.5194e-01,  ...,  4.6572e+00,\n",
      "             2.7272e+00, -2.4256e-01],\n",
      "           [-8.1866e-01,  1.6341e+00, -2.1824e+00,  ..., -2.6393e-01,\n",
      "             2.5778e+00,  9.1552e-01],\n",
      "           [-1.1446e+00,  3.0941e+00, -9.9289e-01,  ..., -1.6537e+00,\n",
      "            -1.0290e-01,  6.4622e-01]],\n",
      "\n",
      "          [[ 2.0945e-01,  9.7471e-01,  1.9135e+00,  ..., -1.7633e+00,\n",
      "             8.5385e-02,  2.7539e-01],\n",
      "           [ 1.3387e+00,  1.5328e+00,  1.2838e+00,  ...,  2.3363e+00,\n",
      "            -1.6075e+00, -1.8921e+00],\n",
      "           [-1.1780e+00, -1.0595e+00, -1.3105e+00,  ...,  1.2442e+00,\n",
      "             1.1369e+00,  8.5974e-01],\n",
      "           ...,\n",
      "           [-6.1788e-01,  2.4880e-02,  1.6346e-01,  ...,  2.2162e+00,\n",
      "            -1.3756e+00, -1.5877e+00],\n",
      "           [ 1.1213e+00,  2.7307e+00, -1.4404e+00,  ...,  8.5259e-01,\n",
      "            -5.5162e-01, -1.0168e+00],\n",
      "           [-1.5226e+00,  2.2577e+00,  1.9849e-01,  ..., -3.4320e+00,\n",
      "             1.0368e+00, -1.3649e+00]],\n",
      "\n",
      "          [[ 2.1740e+00, -3.5988e-01, -4.5201e+00,  ..., -6.9775e-01,\n",
      "             1.1731e+00, -9.3021e-01],\n",
      "           [ 2.3456e+00,  8.8200e-01, -1.1038e+00,  ..., -7.4720e-01,\n",
      "             2.4576e+00,  3.0303e-01],\n",
      "           [-2.0841e+00, -1.3017e+00, -1.1499e+00,  ..., -2.3577e+00,\n",
      "            -1.2172e-01,  1.8501e+00],\n",
      "           ...,\n",
      "           [-1.8029e+00, -8.7136e-01,  3.6063e+00,  ..., -2.1426e+00,\n",
      "             5.8735e-01, -1.3106e+00],\n",
      "           [-1.7447e+00, -2.1457e+00,  1.2505e+00,  ..., -3.1763e-01,\n",
      "            -1.1074e+00, -2.6545e+00],\n",
      "           [-2.5104e+00,  2.8714e+00, -1.1527e+00,  ..., -3.7900e+00,\n",
      "             1.0472e+00,  1.4985e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-3.3915e+00,  4.5277e+00, -1.4848e-01,  ..., -2.2216e+00,\n",
      "            -6.3187e-01,  1.2462e+00],\n",
      "           [ 2.2776e+00,  3.5724e-01, -3.3031e+00,  ...,  1.1997e+00,\n",
      "            -1.0768e+00,  2.5642e+00],\n",
      "           [-2.2815e+00, -4.7451e-02, -1.7560e+00,  ...,  7.6224e-01,\n",
      "            -1.3469e+00,  4.3230e-01],\n",
      "           ...,\n",
      "           [-1.5313e+00,  3.4147e+00,  1.5178e+00,  ...,  7.8105e-01,\n",
      "            -2.0093e+00,  3.3875e+00],\n",
      "           [-1.7264e+00, -2.8033e+00,  5.0559e-01,  ..., -2.7517e+00,\n",
      "            -1.2762e+00,  3.1994e+00],\n",
      "           [ 2.6568e+00,  2.7593e-01,  8.0069e-01,  ..., -2.9219e+00,\n",
      "             1.3171e+00, -1.1203e+00]],\n",
      "\n",
      "          [[ 2.6882e+00, -2.2634e+00, -2.1647e+00,  ..., -2.2313e+00,\n",
      "            -1.5317e+00, -1.8212e+00],\n",
      "           [-1.0633e+00, -5.8482e-01, -2.8523e-01,  ..., -1.7396e-01,\n",
      "             1.7511e+00, -1.9639e+00],\n",
      "           [ 2.7405e+00,  2.6094e+00,  7.7950e-01,  ...,  1.0537e+00,\n",
      "             2.3880e+00, -3.7391e+00],\n",
      "           ...,\n",
      "           [-2.6005e-01,  2.8520e+00, -3.6851e-02,  ...,  1.9212e+00,\n",
      "             1.4060e+00,  1.3096e+00],\n",
      "           [ 2.5795e-01, -1.6583e+00, -9.6179e-01,  ..., -1.7963e+00,\n",
      "             4.3835e-01, -4.4870e-01],\n",
      "           [-3.9503e+00,  1.8160e+00, -2.5193e+00,  ..., -7.1373e-01,\n",
      "             1.1709e+00,  1.2936e+00]],\n",
      "\n",
      "          [[ 1.1112e+00, -9.9333e-01,  2.7781e+00,  ..., -1.1797e+00,\n",
      "             8.3911e-01,  1.5573e+00],\n",
      "           [-3.1838e+00,  6.1916e-01,  2.4010e+00,  ...,  2.9022e+00,\n",
      "             2.3691e-01,  5.0834e-01],\n",
      "           [-5.5208e-01,  4.3114e-01,  4.7062e+00,  ...,  3.3189e+00,\n",
      "            -1.5403e+00,  4.5527e+00],\n",
      "           ...,\n",
      "           [ 4.2758e+00, -1.2818e+00,  8.1801e-01,  ..., -1.4141e-01,\n",
      "             5.1175e-01,  3.9768e+00],\n",
      "           [ 1.2350e+00, -5.7269e-01,  4.7302e-01,  ...,  9.0031e-01,\n",
      "            -1.5532e+00,  4.1605e+00],\n",
      "           [-2.5859e+00,  1.4833e+00,  1.9723e+00,  ...,  4.3809e-01,\n",
      "            -1.3715e-01, -3.4503e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.4552e+00,  1.8589e-01, -7.8303e-01,  ...,  3.1225e+00,\n",
      "             5.8412e-01,  2.9202e+00],\n",
      "           [ 3.8011e-01,  2.0331e+00,  8.7960e-01,  ..., -1.5442e+00,\n",
      "            -6.8804e-02,  1.3328e+00],\n",
      "           [ 2.2165e-01, -2.6249e+00, -4.5026e+00,  ..., -3.3615e+00,\n",
      "            -1.5895e+00,  8.0147e-01],\n",
      "           ...,\n",
      "           [-2.8456e+00,  3.1927e-01,  1.3071e+00,  ...,  2.4191e+00,\n",
      "            -3.1256e+00,  4.8680e-01],\n",
      "           [ 9.5825e-01,  5.1110e+00, -8.2344e-01,  ..., -1.9241e+00,\n",
      "             4.1011e+00,  2.0828e+00],\n",
      "           [-3.7723e-01,  4.4755e-02, -4.4295e-01,  ..., -8.1709e-01,\n",
      "            -1.3682e+00, -5.5263e-01]],\n",
      "\n",
      "          [[ 9.7164e-01,  2.3190e-01, -2.8126e-01,  ...,  2.6591e+00,\n",
      "            -1.6569e-01,  7.1180e-01],\n",
      "           [-3.2809e+00,  2.2947e+00, -2.3350e+00,  ..., -1.2288e+00,\n",
      "             1.0255e+00, -1.5130e+00],\n",
      "           [-5.1557e+00,  8.0739e-01, -5.0879e-01,  ...,  1.2019e+00,\n",
      "            -1.6588e+00, -8.3646e-01],\n",
      "           ...,\n",
      "           [-4.6414e-01, -5.6557e-01, -3.5122e+00,  ...,  1.2754e+00,\n",
      "             1.1172e+00, -3.5610e+00],\n",
      "           [ 2.3743e+00, -3.8163e-01, -6.7870e-01,  ..., -1.6549e-01,\n",
      "            -2.1704e+00,  1.9486e+00],\n",
      "           [ 1.8223e-01, -2.9657e-02,  3.4747e+00,  ..., -2.9681e+00,\n",
      "            -3.8839e+00, -3.0363e+00]],\n",
      "\n",
      "          [[-4.8130e+00, -9.2056e-01,  6.0045e-01,  ...,  4.1466e+00,\n",
      "            -3.1112e+00, -1.2782e+00],\n",
      "           [-1.7544e+00, -2.6759e+00, -1.2452e-01,  ..., -8.0779e-01,\n",
      "             3.4624e-01,  4.8499e+00],\n",
      "           [-3.4520e-01,  1.5930e+00,  1.2867e+00,  ..., -2.4952e-01,\n",
      "            -3.5811e-01, -2.2695e+00],\n",
      "           ...,\n",
      "           [-1.5668e+00,  4.1912e-01,  2.7411e-01,  ..., -9.9155e-02,\n",
      "            -9.1661e-01,  1.4161e+00],\n",
      "           [-9.3888e-02, -1.0455e+00,  1.2352e-01,  ..., -3.4071e+00,\n",
      "            -6.4255e-01,  1.8111e+00],\n",
      "           [-1.6634e+00,  3.6971e+00,  5.2428e+00,  ..., -2.9043e+00,\n",
      "             8.2261e-01,  4.2153e+00]]],\n",
      "\n",
      "\n",
      "         [[[-4.6708e+00,  1.0477e+00, -1.6777e+00,  ..., -4.1665e-01,\n",
      "             5.5397e-01, -9.2220e-01],\n",
      "           [-9.1626e-01, -2.8218e+00, -1.2242e-01,  ..., -2.0470e+00,\n",
      "            -1.6477e+00, -1.2549e+00],\n",
      "           [-6.7821e-01,  2.6044e-01,  1.4909e-01,  ..., -1.7678e-01,\n",
      "             8.9219e-01,  1.1207e+00],\n",
      "           ...,\n",
      "           [-1.2386e+00,  3.2062e+00, -4.6924e+00,  ...,  6.7516e-01,\n",
      "            -1.2415e+00,  4.2830e-01],\n",
      "           [ 1.1344e+00,  1.3350e+00, -1.4419e-01,  ..., -2.3930e+00,\n",
      "             4.7048e+00,  4.3492e-01],\n",
      "           [-3.4175e-01,  1.9881e+00,  1.2068e+00,  ..., -1.5416e+00,\n",
      "             1.4862e+00,  1.9219e+00]],\n",
      "\n",
      "          [[-2.2234e+00, -7.8311e-01, -2.2926e+00,  ..., -1.7873e+00,\n",
      "            -1.1512e+00,  1.0381e+00],\n",
      "           [ 1.0534e+00,  2.2548e+00, -1.9246e+00,  ..., -1.9073e+00,\n",
      "            -2.2532e+00, -1.9009e-01],\n",
      "           [ 3.9103e-01,  4.7318e-01, -2.5445e-01,  ..., -2.6086e+00,\n",
      "             7.1712e-03,  1.9768e+00],\n",
      "           ...,\n",
      "           [-1.7335e+00,  1.5989e+00,  2.1929e+00,  ..., -8.3679e-01,\n",
      "            -2.1336e+00, -7.1277e-01],\n",
      "           [-1.6155e+00, -1.0263e+00, -3.9934e+00,  ...,  2.5615e-01,\n",
      "             9.2984e-01, -1.2816e+00],\n",
      "           [-2.7923e+00, -1.0458e+00, -5.1554e-01,  ...,  3.3969e+00,\n",
      "             1.2814e+00, -1.4070e+00]],\n",
      "\n",
      "          [[-3.5690e-01,  9.6633e-01, -6.2356e-01,  ...,  1.6404e-01,\n",
      "            -2.5748e+00,  1.8884e+00],\n",
      "           [ 1.0890e+00, -1.9004e+00,  1.6001e+00,  ..., -1.5010e+00,\n",
      "             1.2320e+00,  1.7452e-01],\n",
      "           [-2.8014e+00, -4.8812e-01, -1.2634e+00,  ..., -2.0940e+00,\n",
      "            -1.3747e+00,  1.6524e+00],\n",
      "           ...,\n",
      "           [ 3.4074e+00, -8.7292e-01,  2.7938e+00,  ..., -1.3069e+00,\n",
      "             2.0233e+00,  1.5723e-01],\n",
      "           [-2.4311e+00, -8.5052e-01, -3.5763e-03,  ..., -1.2056e+00,\n",
      "             3.7098e+00, -3.3409e+00],\n",
      "           [ 4.3538e-01, -1.1078e+00, -4.5737e-01,  ...,  2.0316e+00,\n",
      "            -9.0934e-01,  1.9568e+00]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.3566e-01,  5.0411e-01,  9.4975e-01,  ...,  1.9862e+00,\n",
      "            -2.2128e+00, -4.0214e+00],\n",
      "           [ 2.0570e+00, -2.3015e+00,  3.5118e+00,  ...,  4.8261e+00,\n",
      "            -1.2321e+00, -3.3191e+00],\n",
      "           [-1.0073e+00,  1.7522e+00,  2.0381e+00,  ..., -8.4621e-01,\n",
      "            -2.4204e-01,  1.7616e+00],\n",
      "           ...,\n",
      "           [-3.8191e+00, -2.4534e+00, -1.4592e+00,  ...,  1.0106e+00,\n",
      "             1.8895e+00,  3.5067e+00],\n",
      "           [ 3.2282e+00, -2.1417e+00,  3.9493e-01,  ...,  5.3944e-01,\n",
      "             3.7562e+00,  1.3583e+00],\n",
      "           [-9.2491e-01, -1.4082e+00,  1.8942e-01,  ..., -4.1528e-01,\n",
      "            -3.0864e+00, -1.0439e+00]],\n",
      "\n",
      "          [[-1.8341e+00,  2.8621e+00, -3.9520e+00,  ...,  8.6085e-01,\n",
      "            -3.0047e+00, -1.3013e+00],\n",
      "           [-2.7939e+00, -1.2013e-01, -3.4941e-01,  ...,  3.1434e+00,\n",
      "            -1.1637e+00,  4.7822e-01],\n",
      "           [ 3.4371e+00,  1.4594e+00, -5.4568e-01,  ..., -2.4335e+00,\n",
      "            -9.5844e-01,  6.7466e-01],\n",
      "           ...,\n",
      "           [ 3.6411e+00, -7.4292e-01, -3.1061e-01,  ..., -2.4131e+00,\n",
      "            -1.1107e+00,  8.0210e-01],\n",
      "           [ 3.4889e+00,  3.0463e+00,  1.7821e+00,  ...,  1.2523e+00,\n",
      "            -2.3137e-01,  1.7421e+00],\n",
      "           [ 1.0949e+00,  2.1049e+00, -4.0996e+00,  ..., -6.2595e-02,\n",
      "             1.0965e+00, -2.2275e+00]],\n",
      "\n",
      "          [[ 3.4232e+00, -5.6806e-01,  2.0793e+00,  ..., -2.7051e+00,\n",
      "            -3.2834e+00,  1.6640e-01],\n",
      "           [ 5.2785e+00,  3.3055e+00,  3.0735e+00,  ...,  1.3630e+00,\n",
      "             1.3806e+00,  4.2004e-01],\n",
      "           [-1.1561e+00, -4.5568e+00,  1.9962e+00,  ..., -5.6854e+00,\n",
      "             1.1639e+00, -1.0375e-01],\n",
      "           ...,\n",
      "           [-2.6681e-01, -2.0793e+00, -7.8791e-01,  ...,  1.6860e-01,\n",
      "            -1.7081e-01,  6.0721e-01],\n",
      "           [-3.2725e+00,  3.3649e-01, -2.6387e+00,  ..., -5.0740e-01,\n",
      "             2.4798e+00, -1.3224e+00],\n",
      "           [ 3.9734e-01, -3.3886e+00,  2.4739e+00,  ..., -3.9416e-02,\n",
      "             2.0039e+00,  1.3241e+00]]],\n",
      "\n",
      "\n",
      "         [[[ 1.3829e+00,  5.8279e-01,  2.7248e-01,  ..., -2.1183e+00,\n",
      "            -4.2976e-01, -1.0081e+00],\n",
      "           [-3.8346e-01,  5.9428e-03,  4.4422e+00,  ..., -6.3062e-01,\n",
      "            -2.2740e+00,  1.6895e+00],\n",
      "           [-2.7474e+00,  2.3128e+00,  1.8951e+00,  ..., -3.6795e-01,\n",
      "            -2.2774e+00, -9.1466e-01],\n",
      "           ...,\n",
      "           [-4.0563e+00,  4.4940e-01,  1.1099e+00,  ...,  5.9653e-01,\n",
      "             1.1540e+00,  1.7325e+00],\n",
      "           [ 6.2871e-01, -2.9092e+00,  9.4933e-02,  ...,  2.5467e+00,\n",
      "             8.2036e-01, -1.3601e+00],\n",
      "           [-2.2489e+00, -1.9888e+00, -2.7451e+00,  ...,  1.1744e+00,\n",
      "             7.2487e-01, -3.8755e+00]],\n",
      "\n",
      "          [[-1.1012e+00,  2.3054e+00, -5.1918e-01,  ..., -9.7741e-01,\n",
      "             1.5996e-01,  7.2345e-01],\n",
      "           [ 1.8672e+00, -1.7043e+00, -2.6742e+00,  ...,  1.5306e+00,\n",
      "            -2.9052e-01,  2.0266e+00],\n",
      "           [ 1.4349e+00,  7.0930e-01,  4.3939e-01,  ..., -1.4465e+00,\n",
      "             5.8308e-01,  1.4952e+00],\n",
      "           ...,\n",
      "           [ 3.2641e+00, -5.6045e-01,  1.7302e+00,  ...,  7.0986e-01,\n",
      "             7.2725e-01, -2.0452e+00],\n",
      "           [ 5.3953e-01, -8.2355e-01, -4.2153e+00,  ..., -2.7125e+00,\n",
      "             1.8739e+00, -7.3450e-01],\n",
      "           [-2.4813e-01, -8.1427e-02,  7.0290e-01,  ...,  5.0491e+00,\n",
      "             8.1782e-01, -7.7862e-01]],\n",
      "\n",
      "          [[ 1.5040e+00, -3.4817e+00,  8.5483e-01,  ..., -2.6807e+00,\n",
      "            -1.0140e+00, -7.0484e-01],\n",
      "           [-9.7333e-01, -4.6175e-02, -2.3728e+00,  ..., -1.3478e+00,\n",
      "            -2.6802e+00, -4.1730e+00],\n",
      "           [-1.5030e+00, -5.8464e-01, -3.7107e+00,  ...,  7.1446e-01,\n",
      "            -1.8595e+00,  1.5147e+00],\n",
      "           ...,\n",
      "           [-2.2546e+00,  3.0875e+00,  1.4930e+00,  ...,  2.6552e+00,\n",
      "            -3.4594e-01,  9.5558e-01],\n",
      "           [-1.2834e+00, -4.5129e-01, -2.7342e+00,  ..., -3.9782e-01,\n",
      "             2.8129e+00,  2.1405e-01],\n",
      "           [-3.8367e+00,  2.0750e+00, -1.9436e+00,  ..., -5.3888e+00,\n",
      "            -3.6551e-01,  1.8943e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.2866e+00, -2.0518e+00,  2.0835e-02,  ..., -1.2355e+00,\n",
      "             4.3180e+00, -1.0796e+00],\n",
      "           [ 3.4957e+00,  1.8532e+00,  6.1050e-01,  ...,  1.0062e+00,\n",
      "             1.5372e+00,  1.5072e+00],\n",
      "           [ 2.1791e+00, -2.2080e+00,  4.0324e-01,  ...,  2.0039e+00,\n",
      "             1.8378e+00,  2.6983e+00],\n",
      "           ...,\n",
      "           [ 3.0000e+00, -7.0696e-01,  2.5139e+00,  ..., -7.0984e-01,\n",
      "             8.4836e-01, -3.4631e+00],\n",
      "           [ 1.2250e+00,  1.0365e+00,  3.0484e+00,  ...,  6.7041e-01,\n",
      "            -7.7362e-01, -8.8820e-01],\n",
      "           [ 4.7337e-02,  1.5759e+00,  1.5688e+00,  ..., -5.2963e+00,\n",
      "            -1.0311e+00,  1.7890e+00]],\n",
      "\n",
      "          [[-6.4871e-01,  6.2949e-01, -3.7981e-01,  ...,  2.7964e+00,\n",
      "            -1.4561e-01,  1.1356e-01],\n",
      "           [ 3.2006e+00,  2.0124e+00,  1.2723e+00,  ..., -3.8771e+00,\n",
      "             1.1074e+00,  1.1944e-01],\n",
      "           [ 3.9460e-01, -4.8509e-01,  8.7109e-01,  ...,  7.4026e-01,\n",
      "             3.1017e+00,  2.0200e+00],\n",
      "           ...,\n",
      "           [ 5.4508e-01,  2.2133e+00, -8.7976e-01,  ..., -2.6748e+00,\n",
      "             7.7322e-01,  2.7053e+00],\n",
      "           [ 1.1746e-01, -2.4357e+00,  1.1808e+00,  ...,  2.7157e+00,\n",
      "            -9.5083e-01, -9.6711e-01],\n",
      "           [ 1.4384e+00, -1.1582e+00, -4.1484e-01,  ..., -1.1918e+00,\n",
      "            -8.4184e-01, -8.8431e-01]],\n",
      "\n",
      "          [[ 2.1761e+00, -1.3223e+00, -7.1647e-01,  ..., -3.2714e+00,\n",
      "             5.4847e+00,  2.9853e-01],\n",
      "           [ 1.2424e+00,  2.4429e+00, -1.0986e+00,  ...,  1.4314e+00,\n",
      "            -1.5966e+00, -1.7830e+00],\n",
      "           [ 2.7502e+00, -1.5976e+00,  1.5186e+00,  ..., -6.9456e-01,\n",
      "             1.6545e+00,  1.0316e+00],\n",
      "           ...,\n",
      "           [ 6.2586e-01,  1.6280e+00,  9.1412e-01,  ...,  8.2107e-01,\n",
      "            -2.1762e+00, -1.0640e+00],\n",
      "           [-1.3603e+00, -3.8494e+00, -5.5597e-01,  ...,  3.4255e+00,\n",
      "             4.9164e-01,  1.4557e+00],\n",
      "           [ 1.2839e+00,  7.2343e-01,  2.4763e+00,  ...,  3.1818e-01,\n",
      "             1.2537e+00,  2.6888e+00]]],\n",
      "\n",
      "\n",
      "         [[[-2.8830e+00, -1.0274e+00, -1.0832e-01,  ...,  2.7925e+00,\n",
      "             2.0609e-01, -2.4293e+00],\n",
      "           [-2.8273e+00, -8.8152e-01, -2.3785e+00,  ..., -1.0434e+00,\n",
      "             2.1875e+00,  3.2217e+00],\n",
      "           [-8.8851e-02, -3.3145e-01, -5.1933e-02,  ..., -7.4743e-01,\n",
      "            -1.4081e+00, -2.8333e+00],\n",
      "           ...,\n",
      "           [ 8.9943e-01, -1.6347e+00, -1.7086e+00,  ..., -7.5519e-01,\n",
      "            -5.1622e-01, -3.6188e+00],\n",
      "           [-3.3312e+00,  1.1552e-01, -5.3399e-01,  ...,  1.8658e+00,\n",
      "            -4.3640e-01, -3.3044e+00],\n",
      "           [-6.4896e-01,  3.4611e-01, -1.7796e+00,  ...,  2.1600e-02,\n",
      "            -8.7373e-01,  5.3120e+00]],\n",
      "\n",
      "          [[-3.4569e+00, -3.7948e-01,  1.4097e+00,  ...,  2.0217e+00,\n",
      "            -1.2107e+00,  1.3903e-01],\n",
      "           [ 1.8430e+00,  1.7636e+00,  1.0442e+00,  ..., -1.3836e+00,\n",
      "            -2.8621e+00, -1.0463e+00],\n",
      "           [-1.9797e+00,  3.0680e+00, -2.9148e+00,  ..., -2.4756e+00,\n",
      "            -2.4738e+00,  7.1424e-01],\n",
      "           ...,\n",
      "           [-1.1930e+00,  1.6424e+00,  1.1125e+00,  ..., -1.2895e+00,\n",
      "            -4.1638e+00, -1.3199e+00],\n",
      "           [ 2.1066e+00,  1.2928e+00, -5.8107e-01,  ...,  3.3982e-01,\n",
      "             1.3632e+00,  2.0253e-02],\n",
      "           [ 9.1244e-01, -2.1803e+00, -1.8910e-01,  ..., -1.8506e+00,\n",
      "             5.9805e-01, -1.2650e-02]],\n",
      "\n",
      "          [[ 1.1556e+00,  5.5966e-01, -2.9152e+00,  ...,  1.8701e+00,\n",
      "             4.8531e+00,  2.3713e-01],\n",
      "           [ 1.8593e+00, -3.1846e+00,  1.5341e+00,  ...,  2.0076e+00,\n",
      "             8.6852e-01, -2.5621e+00],\n",
      "           [ 1.9849e+00, -1.6562e+00,  3.1896e+00,  ..., -1.1457e+00,\n",
      "             2.1844e+00,  7.7318e-01],\n",
      "           ...,\n",
      "           [ 2.0515e+00, -1.9933e+00, -1.3025e+00,  ..., -1.3150e+00,\n",
      "            -9.4300e-01, -4.9630e-01],\n",
      "           [ 1.5610e-01, -2.8873e-01,  4.4567e-01,  ..., -1.9379e+00,\n",
      "             4.2317e+00, -1.6020e-02],\n",
      "           [-6.7766e-01, -4.3412e-01, -1.0681e+00,  ...,  4.0976e-01,\n",
      "            -4.5360e+00, -9.5822e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-7.4386e-01,  5.4618e-01, -3.6345e-01,  ...,  1.4416e+00,\n",
      "            -2.1034e+00, -3.4274e+00],\n",
      "           [-4.5574e-01,  2.9245e+00, -1.2251e+00,  ...,  6.5341e-01,\n",
      "             2.6107e+00, -1.7481e+00],\n",
      "           [ 9.9478e-01, -9.8438e-01,  1.6271e+00,  ...,  5.0412e-01,\n",
      "            -8.4240e-01,  1.2300e+00],\n",
      "           ...,\n",
      "           [ 2.3794e+00, -7.2722e-01,  8.2056e-01,  ...,  1.6038e+00,\n",
      "            -5.9900e-01,  2.9228e+00],\n",
      "           [-3.2270e+00, -1.3272e+00,  4.2359e-01,  ..., -6.7514e-01,\n",
      "             2.1536e+00,  2.3596e+00],\n",
      "           [ 2.8193e+00,  2.0847e+00, -1.3128e+00,  ..., -2.0456e+00,\n",
      "            -2.9068e+00,  2.1366e-01]],\n",
      "\n",
      "          [[ 4.2895e+00,  1.6850e+00,  4.7504e-01,  ...,  3.4320e+00,\n",
      "            -9.9629e-01, -7.3289e-01],\n",
      "           [ 1.2739e+00,  1.3900e+00, -1.3468e+00,  ..., -1.5876e+00,\n",
      "             6.9388e-01,  5.7247e-01],\n",
      "           [ 6.6841e-01,  1.8712e-01, -5.1638e-01,  ..., -8.3624e-01,\n",
      "             1.9643e-01,  2.8576e+00],\n",
      "           ...,\n",
      "           [ 1.6322e+00,  3.1392e+00, -1.1587e+00,  ..., -4.4815e+00,\n",
      "            -1.1464e+00,  1.4800e+00],\n",
      "           [-7.0567e-01, -3.7300e+00,  4.2416e-01,  ..., -3.2136e+00,\n",
      "             2.4277e+00, -3.7890e-01],\n",
      "           [ 8.1870e-02, -3.7791e+00,  6.1423e-03,  ..., -2.9177e-01,\n",
      "             6.9520e-01,  3.5259e+00]],\n",
      "\n",
      "          [[ 1.2996e+00, -2.0428e+00, -2.5223e+00,  ..., -1.8771e-01,\n",
      "             1.7696e-01, -2.0761e-01],\n",
      "           [ 2.5680e+00,  3.9341e+00,  1.1144e+00,  ..., -7.8549e-01,\n",
      "            -1.3430e+00, -3.0066e-01],\n",
      "           [ 2.8009e+00, -4.2910e+00, -3.2290e+00,  ..., -2.4094e-01,\n",
      "            -2.5488e+00,  3.0217e+00],\n",
      "           ...,\n",
      "           [-4.7170e+00,  4.2315e+00, -2.1562e+00,  ..., -7.0969e-01,\n",
      "             1.1554e+00,  2.2696e-01],\n",
      "           [-8.2638e-01,  2.1354e+00, -1.8922e+00,  ...,  2.6673e+00,\n",
      "             7.3619e-01, -1.2641e+00],\n",
      "           [ 1.3161e+00, -1.9127e+00,  1.4818e+00,  ..., -1.3330e+00,\n",
      "             1.8047e+00, -5.5021e-01]]]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.Dropout3d\n",
    "dropout3d_layer = nn.Dropout3d(p=0.5)\n",
    "input_data = torch.randn(3, 4, 10, 10, 10)  # 3 个样本，4 个通道，10x10x10 大小的特征图\n",
    "output = dropout3d_layer(input_data)\n",
    "\n",
    "print(output)  # 整个通道将被置为 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7792,  0.7763,  0.6064, -0.7792],\n",
      "        [-0.7792,  0.8955, -0.7792,  0.7126],\n",
      "        [-0.7792, -0.7792,  1.1647, -0.7792]])\n"
     ]
    }
   ],
   "source": [
    "# nn.AlphaDropout 是一种特殊的 Dropout，主要用于 SELU 激活函数，以保证均值和方差不变。\n",
    "alpha_dropout_layer = nn.AlphaDropout(p=0.5)\n",
    "input_data = torch.randn(3, 4)\n",
    "output = alpha_dropout_layer(input_data)\n",
    "\n",
    "print(output)  # 一部分输入会被随机置为 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792,\n",
      "          -0.7792, -0.7792, -0.7792],\n",
      "         [-0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792,\n",
      "          -0.7792, -0.7792, -0.7792],\n",
      "         [ 0.7312,  0.7215,  1.0061, -0.1258,  0.8800,  0.0375,  1.2197,\n",
      "           1.2128, -0.2303,  0.1198],\n",
      "         [ 1.8267,  0.8541, -0.2851,  0.2515,  0.1064,  1.4023,  0.5962,\n",
      "          -0.0202, -0.1699,  0.2069]],\n",
      "\n",
      "        [[ 0.4767,  1.3892,  3.1136, -0.3216,  2.1921,  0.8499,  1.0830,\n",
      "           1.0773,  1.6652,  2.0447],\n",
      "         [ 0.7447,  0.0246,  1.9605,  1.3564,  0.8277,  1.6889,  0.0721,\n",
      "           1.3913,  2.3715,  1.4535],\n",
      "         [-0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792,\n",
      "          -0.7792, -0.7792, -0.7792],\n",
      "         [ 0.1083,  2.2539,  1.3623,  1.3676,  1.2805,  1.0769, -0.5790,\n",
      "           1.8392,  0.9436,  0.6383]],\n",
      "\n",
      "        [[ 1.1084,  1.2945,  1.9404,  0.6845,  2.3187, -1.2364,  0.5870,\n",
      "          -0.6565,  1.5612,  0.3740],\n",
      "         [ 1.1210,  0.4662,  2.2505,  1.6680,  0.2291,  2.7458,  1.5220,\n",
      "          -0.8074,  0.1096,  1.1892],\n",
      "         [-0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792, -0.7792,\n",
      "          -0.7792, -0.7792, -0.7792],\n",
      "         [ 1.0063,  1.2016,  1.1604,  1.0195,  0.7761, -0.0197,  0.7542,\n",
      "           0.5987,  1.4628,  0.0647]]])\n"
     ]
    }
   ],
   "source": [
    "# nn.FeatureAlphaDropout 类似于 AlphaDropout，但它会随机将整个特征通道置为 0。\n",
    "feature_alpha_dropout_layer = nn.FeatureAlphaDropout(p=0.5)\n",
    "input_data = torch.randn(3, 4, 10)  # 3 个样本，4 个通道，10 个特征\n",
    "output = feature_alpha_dropout_layer(input_data)\n",
    "\n",
    "print(output)  # 整个通道将被随机置为 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Layers Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6502,  2.3064,  0.1625],\n",
      "        [ 0.1200,  1.4873, -0.9191],\n",
      "        [ 0.0973, -1.4780, -0.3336],\n",
      "        [-0.0181, -0.9556,  0.3699]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个包含 10 个单词，每个单词嵌入为 3 维向量的 Embedding 层\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=3)\n",
    "\n",
    "# 输入是单词的索引（这里假设词典中的索引是 [0, 1, 2, ...]）\n",
    "input_indices = torch.tensor([1, 2, 6, 8])\n",
    "\n",
    "# 通过 embedding 查找对应的嵌入向量\n",
    "output = embedding(input_indices)\n",
    "\n",
    "print(output)  # 输出 [4, 3] 的嵌入向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6909, -0.1191,  0.7472],\n",
      "        [ 0.5338, -1.1827, -0.7355]], grad_fn=<EmbeddingBagBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 创建一个包含 10 个单词，每个单词嵌入为 3 维向量的 EmbeddingBag 层\n",
    "embedding_bag = nn.EmbeddingBag(num_embeddings=10, embedding_dim=3, mode='mean') # 或 'sum' 或 'max'\n",
    "\n",
    "# 输入是一个单词索引的 batch（多个 bag），并且每个 bag 的长度是可变的\n",
    "input_indices = torch.tensor([1, 2, 5, 8])\n",
    "offsets = torch.tensor([0, 2])  # 表示两个 bag，第一个 bag 是 [1, 2]，第二个 bag 是 [5, 8]\n",
    "# offsets 表示每个 bag 的起始位置，即input_indices[0]和input_indices[2]\n",
    "\n",
    "# 通过 embedding_bag 查找对应的嵌入向量，并对每个 bag 内的向量求平均\n",
    "output = embedding_bag(input_indices, offsets)\n",
    "\n",
    "print(output)  # 输出 [2, 3] 的 bag 平均嵌入\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "余弦相似度:  tensor([1.0000, 0.9982])\n"
     ]
    }
   ],
   "source": [
    "# nn.CosineSimilarity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 初始化两个向量（这里假设有3个维度）\n",
    "x1 = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])  # Shape: (2, 3)\n",
    "x2 = torch.tensor([[1.0, 2.0, 3.0], [7.0, 8.0, 9.0]])  # Shape: (2, 3)\n",
    "\n",
    "# 初始化 nn.CosineSimilarity，指定计算相似度的维度为最后一维\n",
    "cos = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "# 计算两个向量之间的余弦相似度\n",
    "similarity = cos(x1, x2)\n",
    "\n",
    "print(\"余弦相似度: \", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成对距离:  tensor([1.7321e-06, 5.1962e+00])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 初始化两个向量，每个包含两个样本，每个样本有三个特征\n",
    "x1 = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])  # Shape: (2, 3)\n",
    "x2 = torch.tensor([[1.0, 2.0, 3.0], [7.0, 8.0, 9.0]])  # Shape: (2, 3)\n",
    "\n",
    "# 初始化 nn.PairwiseDistance 实例\n",
    "pairwise_dist = nn.PairwiseDistance(p=2)  # p=2 表示欧氏距离\n",
    "\n",
    "# 计算每对向量之间的距离\n",
    "distance = pairwise_dist(x1, x2)\n",
    "\n",
    "print(\"成对距离: \", distance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **nn.L1Loss**\n",
    "   - **用途**：L1 损失函数通常用于回归任务中，用来计算输入和目标值之间的**平均绝对误差**（MAE）。\n",
    "   - **特点**：对**离群点**比较敏感，因为它对每个误差的绝对值进行平均处理，因此适合需要对误差较小的任务更敏感的场景。\n",
    "\n",
    "### 2. **nn.MSELoss**\n",
    "   - **用途**：常用于回归问题中，计算输入和目标之间的**均方误差**。\n",
    "   - **特点**：更关注大的误差，惩罚较大的误差，适合场景中较大的误差需要额外处理的情况。\n",
    "\n",
    "### 3. **nn.CrossEntropyLoss**\n",
    "   - **用途**：用于**分类问题**，特别是多类分类问题。它计算输入的**logits**和目标类别的交叉熵损失。\n",
    "   - **特点**：将`nn.LogSoftmax`和`nn.NLLLoss`结合在一起，适合用于需要概率输出的分类任务。\n",
    "\n",
    "### 4. **nn.CTCLoss**\n",
    "   - **用途**：用于**序列建模任务**，如语音识别，OCR等。它可以处理不对齐的输入序列和目标序列。\n",
    "   - **特点**：支持**可变长度**的输出序列，对目标序列进行无对齐计算。\n",
    "\n",
    "### 5. **nn.NLLLoss**\n",
    "   - **用途**：用于分类问题，输入是对数概率（log-probabilities），用于测量负对数似然损失。\n",
    "   - **特点**：通常与`nn.LogSoftmax`结合使用，适用于**概率估计**和分类任务。\n",
    "\n",
    "### 6. **nn.PoissonNLLLoss**\n",
    "   - **用途**：用于**计数预测问题**，其中目标服从**泊松分布**。\n",
    "   - **特点**：适用于目标是非负整数并且符合泊松分布的任务，如事件计数问题。\n",
    "\n",
    "### 7. **nn.GaussianNLLLoss**\n",
    "   - **用途**：用于**回归任务**，假设目标值服从**高斯分布**。\n",
    "   - **特点**：适用于目标具有均值和方差，并且符合高斯分布的情况。\n",
    "\n",
    "### 8. **nn.KLDivLoss**\n",
    "   - **用途**：用于计算两个概率分布之间的**Kullback-Leibler (KL) 散度**。\n",
    "   - **特点**：通常用于训练变分自编码器（VAE）等场景中，用于测量两个分布的差异。\n",
    "\n",
    "### 9. **nn.BCELoss**\n",
    "   - **用途**：用于**二分类问题**，测量输入和目标的二元交叉熵。\n",
    "   - **特点**：输出值应是概率（通常通过`Sigmoid`函数获得），适用于需要二分类的任务。\n",
    "\n",
    "### 10. **nn.BCEWithLogitsLoss**\n",
    "   - **用途**：结合了`Sigmoid`和`BCELoss`，用于二分类问题，避免了数值不稳定问题。\n",
    "   - **特点**：比直接使用`BCELoss`更加稳定高效，因为将Sigmoid与损失计算合并为一个步骤。\n",
    "\n",
    "### 11. **nn.MarginRankingLoss**\n",
    "   - **用途**：用于**排序任务**，比较两个输入向量的大小差异，要求标签为1或-1。\n",
    "   - **特点**：适用于信息检索、推荐系统等排序问题。\n",
    "\n",
    "### 12. **nn.HingeEmbeddingLoss**\n",
    "   - **用途**：用于**相似度学习**，用于嵌入向量的衡量，目标标签为1或-1。\n",
    "   - **特点**：适合分类或度量学习中的正负样本对比任务。\n",
    "\n",
    "### 13. **nn.MultiLabelMarginLoss**\n",
    "   - **用途**：用于**多标签分类**任务，优化多类多标签的 hinge 损失。\n",
    "   - **特点**：适用于需要处理多个目标标签的场景，如图像标注任务。\n",
    "\n",
    "### 14. **nn.HuberLoss**\n",
    "   - **用途**：用于回归任务，结合了`L1`和`L2`损失的优点。\n",
    "   - **特点**：当误差较小时使用`L2`，误差较大时使用`L1`，适合处理**异常值**和**稳健回归**。\n",
    "\n",
    "### 15. **nn.SmoothL1Loss**\n",
    "   - **用途**：常用于目标检测等任务，损失在小误差时为平方项，大误差时为线性项。\n",
    "   - **特点**：相比`MSELoss`更平滑和鲁棒，适用于回归问题中需要处理**异常值**的场景。\n",
    "\n",
    "### 16. **nn.SoftMarginLoss**\n",
    "   - **用途**：用于二分类任务，使用逻辑回归损失来优化。\n",
    "   - **特点**：目标标签为1或-1，适用于二分类问题。\n",
    "\n",
    "### 17. **nn.MultiLabelSoftMarginLoss**\n",
    "   - **用途**：用于**多标签分类**，优化基于最大熵的多标签 one-vs-all 损失。\n",
    "   - **特点**：适用于多标签分类任务，如文本分类。\n",
    "\n",
    "### 18. **nn.CosineEmbeddingLoss**\n",
    "   - **用途**：用于**相似度学习**，根据两个输入向量的余弦相似度衡量它们的相似性。\n",
    "   - **特点**：在度量学习和相似度任务中常见，用于如人脸识别等。\n",
    "\n",
    "### 19. **nn.MultiMarginLoss**\n",
    "   - **用途**：用于**多类分类**任务，基于 hinge 损失。\n",
    "   - **特点**：适用于需要分类多个类别的场景，通常与SVM类似。\n",
    "\n",
    "### 20. **nn.TripletMarginLoss**\n",
    "   - **用途**：用于**度量学习**中的三元组损失，衡量锚点、正样本和负样本之间的相对距离。\n",
    "   - **特点**：常用于人脸识别和推荐系统中的相似度度量。\n",
    "\n",
    "### 21. **nn.TripletMarginWithDistanceLoss**\n",
    "   - **用途**：扩展三元组损失，允许使用不同的**距离函数**来计算损失。\n",
    "   - **特点**：适用于自定义距离度量的三元组学习任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vision layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **nn.PixelShuffle**\n",
    "   - **用途**：将一个低分辨率的特征图重新排列成更高分辨率的特征图，通常用于**超分辨率**任务。\n",
    "   - **特点**：输入是一个包含多个通道的特征图，经过重排列后通道数减少，空间维度增加。常用于提高图像分辨率时的最后一步。\n",
    "\n",
    "### 2. **nn.PixelUnshuffle**\n",
    "   - **用途**：执行与`PixelShuffle`相反的操作，将高分辨率图像重新排列成低分辨率的特征图。\n",
    "   - **特点**：减少空间维度，增加通道数，适用于需要降维或特征提取的场景。\n",
    "\n",
    "### 3. **nn.Upsample**\n",
    "   - **用途**：对输入的1D、2D或3D多通道数据进行上采样，增加分辨率。\n",
    "   - **特点**：可以指定插值方式（如`nearest`或`linear`），适用于**图像增强**或特征图的放大。\n",
    "\n",
    "### 4. **nn.UpsamplingNearest2d**\n",
    "   - **用途**：对2D输入信号（如图像）使用最近邻插值方法进行上采样。\n",
    "   - **特点**：插值方式简单，计算效率高，但插值结果不如其他方法平滑，适用于需要快速上采样的场景。\n",
    "\n",
    "### 5. **nn.UpsamplingBilinear2d**\n",
    "   - **用途**：对2D输入信号使用双线性插值方法进行上采样。\n",
    "   - **特点**：相比最近邻插值，双线性插值可以生成更平滑的图像，适用于对图像质量要求较高的上采样任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PixelShuffle Output:\n",
      " tensor([[[[ 0.9690,  0.2592,  0.5729,  0.4074],\n",
      "          [ 0.0354, -0.3096,  0.1912,  0.0859],\n",
      "          [-0.0361, -0.6968,  1.9412,  0.4971],\n",
      "          [-0.9405,  0.0198,  0.2116,  0.6856]]]])\n",
      "PixelUnshuffle Output:\n",
      " tensor([[[[ 0.9690, -0.0361],\n",
      "          [ 0.0354, -0.9405]],\n",
      "\n",
      "         [[ 0.5729,  1.9412],\n",
      "          [ 0.1912,  0.2116]],\n",
      "\n",
      "         [[ 0.2592, -0.6968],\n",
      "          [-0.3096,  0.0198]],\n",
      "\n",
      "         [[ 0.4074,  0.4971],\n",
      "          [ 0.0859,  0.6856]]]])\n",
      "Upsample Output:\n",
      " tensor([[[[ 0.9690,  0.8700,  0.6719,  0.4207,  0.1162,  0.4583,  1.4469,\n",
      "            1.9412],\n",
      "          [ 0.7915,  0.7265,  0.5965,  0.3484, -0.0180,  0.2441,  1.1348,\n",
      "            1.5801],\n",
      "          [ 0.4367,  0.4397,  0.4458,  0.2037, -0.2865, -0.1842,  0.5107,\n",
      "            0.8581],\n",
      "          [ 0.2033,  0.2408,  0.3158,  0.0756, -0.4799, -0.4619,  0.1299,\n",
      "            0.4257],\n",
      "          [ 0.0914,  0.1299,  0.2068, -0.0359, -0.5983, -0.5889, -0.0076,\n",
      "            0.2830],\n",
      "          [-0.0508,  0.0031,  0.1110, -0.0514, -0.4841, -0.4428,  0.0725,\n",
      "            0.3301],\n",
      "          [-0.2234, -0.1395,  0.0283,  0.0291, -0.1371, -0.0234,  0.3703,\n",
      "            0.5671],\n",
      "          [-0.3096, -0.2107, -0.0130,  0.0694,  0.0363,  0.1863,  0.5192,\n",
      "            0.6856]]]])\n",
      "UpsamplingNearest2d Output:\n",
      " tensor([[[[ 0.9690,  0.9690,  0.5729,  0.5729, -0.0361, -0.0361,  1.9412,\n",
      "            1.9412],\n",
      "          [ 0.9690,  0.9690,  0.5729,  0.5729, -0.0361, -0.0361,  1.9412,\n",
      "            1.9412],\n",
      "          [ 0.2592,  0.2592,  0.4074,  0.4074, -0.6968, -0.6968,  0.4971,\n",
      "            0.4971],\n",
      "          [ 0.2592,  0.2592,  0.4074,  0.4074, -0.6968, -0.6968,  0.4971,\n",
      "            0.4971],\n",
      "          [ 0.0354,  0.0354,  0.1912,  0.1912, -0.9405, -0.9405,  0.2116,\n",
      "            0.2116],\n",
      "          [ 0.0354,  0.0354,  0.1912,  0.1912, -0.9405, -0.9405,  0.2116,\n",
      "            0.2116],\n",
      "          [-0.3096, -0.3096,  0.0859,  0.0859,  0.0198,  0.0198,  0.6856,\n",
      "            0.6856],\n",
      "          [-0.3096, -0.3096,  0.0859,  0.0859,  0.0198,  0.0198,  0.6856,\n",
      "            0.6856]]]])\n",
      "UpsamplingBilinear2d Output:\n",
      " tensor([[[[ 0.9690,  0.7992,  0.6295,  0.3989,  0.1379,  0.2464,  1.0938,\n",
      "            1.9412],\n",
      "          [ 0.6648,  0.5950,  0.5253,  0.2674, -0.0846, -0.0847,  0.6188,\n",
      "            1.3223],\n",
      "          [ 0.3606,  0.3908,  0.4210,  0.1358, -0.3071, -0.4159,  0.1438,\n",
      "            0.7034],\n",
      "          [ 0.1953,  0.2597,  0.3242,  0.0279, -0.4487, -0.5976, -0.0910,\n",
      "            0.4155],\n",
      "          [ 0.0994,  0.1652,  0.2311, -0.0681, -0.5497, -0.7046, -0.2057,\n",
      "            0.2932],\n",
      "          [-0.0139,  0.0676,  0.1490, -0.1037, -0.5234, -0.6486, -0.1846,\n",
      "            0.2793],\n",
      "          [-0.1617, -0.0363,  0.0892, -0.0183, -0.2424, -0.2668,  0.1078,\n",
      "            0.4825],\n",
      "          [-0.3096, -0.1401,  0.0294,  0.0670,  0.0387,  0.1149,  0.4003,\n",
      "            0.6856]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 输入张量，假设是一个2D图像，形状为(batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(1, 1, 4, 4)  # 1个样本，1个通道，4x4的图像\n",
    "\n",
    "# 1. nn.PixelShuffle这里将输入的4通道(2x2)张量上采样为1通道(4x4)，这里将特征图拓展了，但是将通道数减少了\n",
    "def pixel_shuffle_example(input_tensor, upscale_factor):\n",
    "    # 在这里，我们需要调整通道数以使用PixelShuffle\n",
    "    # 比如，将输入的通道数调整为 (upscale_factor^2) * c\n",
    "    # 在这个例子中，假设我们要将 1 个通道转变为 4 个通道 (2x2)\n",
    "    input_tensor = input_tensor.view(1, 4, 2, 2)  # 1个样本，4个通道，2x2\n",
    "    pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "    output_pixel_shuffle = pixel_shuffle(input_tensor)\n",
    "    return output_pixel_shuffle\n",
    "\n",
    "print(\"PixelShuffle Output:\\n\", pixel_shuffle_example(input_tensor, upscale_factor=2))\n",
    "\n",
    "\n",
    "# 2. nn.PixelUnshuffle将输入的张量恢复到低分辨率，输出的是多个通道，也就是将特征图缩小，对应使通道数增加\n",
    "def pixel_unshuffle_example(input_tensor, upscale_factor):\n",
    "    pixel_unshuffle = nn.PixelUnshuffle(upscale_factor)\n",
    "    # 假设我们已经有了一个输出形状为 (1, 4, 4, 4)，即输入形状为 (1, 1, 4, 4)\n",
    "    input_tensor = input_tensor.view(1, 1, 4, 4)  # 1个样本，1个通道，4x4\n",
    "    output_pixel_unshuffle = pixel_unshuffle(input_tensor)\n",
    "    return output_pixel_unshuffle\n",
    "\n",
    "print(\"PixelUnshuffle Output:\\n\", pixel_unshuffle_example(input_tensor, upscale_factor=2))\n",
    "\n",
    "\n",
    "# 3. nn.Upsample直接对输入张量上采样到8x8的分辨率。\n",
    "def upsample_example(input_tensor):\n",
    "    upsample = nn.Upsample(size=(8, 8), mode='bilinear', align_corners=False)\n",
    "    output_upsample = upsample(input_tensor)\n",
    "    return output_upsample\n",
    "\n",
    "print(\"Upsample Output:\\n\", upsample_example(input_tensor))\n",
    "\n",
    "\n",
    "# 4. nn.UpsamplingNearest2d使用最近邻插值方法将张量上采样到8x8。\n",
    "def upsampling_nearest_example(input_tensor):\n",
    "    upsampling_nearest = nn.UpsamplingNearest2d(size=(8, 8))\n",
    "    output_upsampling_nearest = upsampling_nearest(input_tensor)\n",
    "    return output_upsampling_nearest\n",
    "\n",
    "print(\"UpsamplingNearest2d Output:\\n\", upsampling_nearest_example(input_tensor))\n",
    "\n",
    "\n",
    "# 5. nn.UpsamplingBilinear2d使用双线性插值方法将张量上采样到8x8。\n",
    "def upsampling_bilinear_example(input_tensor):\n",
    "    upsampling_bilinear = nn.UpsamplingBilinear2d(size=(8, 8))\n",
    "    output_upsampling_bilinear = upsampling_bilinear(input_tensor)\n",
    "    return output_upsampling_bilinear\n",
    "\n",
    "print(\"UpsamplingBilinear2d Output:\\n\", upsampling_bilinear_example(input_tensor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor Shape:  torch.Size([1, 4, 4, 4])\n",
      "Output Tensor Shape:  torch.Size([1, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个输入张量，假设形状为 (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(1, 4, 4, 4)  # 1个样本，4个通道，4x4的图像\n",
    "\n",
    "# 定义 ChannelShuffle 函数\n",
    "def channel_shuffle_example(input_tensor, groups):\n",
    "    channel_shuffle = nn.ChannelShuffle(groups)\n",
    "    output_channel_shuffle = channel_shuffle(input_tensor)\n",
    "    return output_channel_shuffle\n",
    "\n",
    "# 使用 2 组来进行通道混洗\n",
    "groups = 2\n",
    "output = channel_shuffle_example(input_tensor, groups)\n",
    "\n",
    "print(\"Input Tensor Shape: \", input_tensor.shape)\n",
    "print(\"Output Tensor Shape: \", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
